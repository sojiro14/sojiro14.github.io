---
title: "WaveNet: A Generative Model for Raw Audio"
date: 2016-09-19
comments: true
categories: [Computer Science, Sound]
---

# WaveNet: A Generative Model for Raw Audio
- <https://arxiv.org/abs/1609.03499>
- <https://arxiv.org/pdf/1609.03499>

---
## WaveNet: 生の音声データに対する生成モデル

## 1. はじめに

WaveNetは、生の音声波形を直接モデル化する深層生成モデルです。このモデルは、以下の特徴を持っています:

- 完全に確率的で自己回帰的
- 各音声サンプルの予測分布は、それ以前のすべてのサンプルに条件付けられる
- 1秒あたり数万サンプルの音声データを効率的に学習可能

WaveNetは以下の分野で優れた性能を示しました:

- テキスト音声合成(TTS)において、人間のリスナーが最も自然だと評価
- 英語と中国語の両方で、パラメトリック方式と連結方式の最高システムを上回る
- 1つのWaveNetで多数の話者の特徴を同等の忠実度で捉えられる
- 話者IDを条件として与えることで、異なる話者の音声を生成可能
- 音楽のモデル化において、新規性が高く現実的な音楽フラグメントを生成
- 音素認識などの識別モデルとしても有望な結果

## 2. WaveNetの構造

### 2.1 希釈因果畳み込み

WaveNetの主要な構成要素は因果畳み込みです。これにより、モデルがデータのモデル化順序に違反しないようにしています。

![Dilated Causal Convolutions](https://github.com/user-attachments/assets/a9ee7e80-aafa-439c-a88e-5cc262dd3cd2)

希釈畳み込みを使用することで、受容野を大幅に拡大しつつ、計算コストを抑えています。

### 2.2 ソフトマックス分布

WaveNetは、各時点の音声サンプルの条件付き分布をソフトマックス分布でモデル化します。これにより、任意の分布を柔軟にモデル化できます。

生の音声データは通常16ビット整数値で保存されるため、65,536の出力を持つソフトマックス層が必要になります。これを扱いやすくするために、μ法圧縮変換を適用し、256の値に量子化しています。

### 2.3 ゲート付き活性化ユニット

WaveNetは、以下のようなゲート付き活性化ユニットを使用します:

```
z = tanh(Wf,k * x) ⊙ σ(Wg,k * x)
```

ここで、⊙は要素ごとの乗算、σ(·)はシグモイド関数、kは層のインデックス、fとgはそれぞれフィルターとゲートを表し、Wは学習可能な畳み込みフィルターです。

### 2.4 残差接続とスキップ接続

モデルの収束を速め、より深いネットワークの学習を可能にするために、残差接続とパラメータ化されたスキップ接続を使用しています。

![Residual and Skip Connections](https://github.com/user-attachments/assets/061f6420-f13c-4dec-82d9-2ca637e5998b)

### 2.5 条件付きWaveNet

追加の入力hを与えることで、WaveNetは条件付き分布p(x|h)をモデル化できます。条件付けには、グローバル条件付けとローカル条件付けの2種類があります。

## 3. 実験

### 3.1 複数話者の音声生成

VCTKコーパスを使用し、109人の話者の44時間のデータセットで学習を行いました。テキストに条件付けせずに自由形式の音声を生成しました。

結果:
- 存在しないが人間の言語に似た単語を滑らかに生成
- 1つのWaveNetで109人全ての話者の特徴を捉えることができた
- 話者を増やすことで検証セットのパフォーマンスが向上
- 音声以外の特徴（音響、録音品質、呼吸、口の動きなど）も模倣

### 3.2 テキスト音声合成(TTS)

北米英語と中国語標準語のそれぞれ24.6時間と34.8時間のデータセットを使用しました。

結果:
- WaveNetは、ベースラインのパラメトリック方式と連結方式の音声合成システムを上回りました
- 5段階の自然性MOSで4.0以上を達成（過去最高スコア）
- 最高の合成音声と自然音声とのMOSの差を、英語で51%、中国語で69%縮小

![TTS Preference Scores](https://github.com/user-attachments/assets/db6c6211-deef-4fc8-a844-7bf5b348d4d2)

### 3.3 音楽

MagnaTagATuneデータセット（約200時間）とYouTubeピアノデータセット（約60時間）を使用しました。

結果:
- 受容野を拡大することが音楽的なサンプルを生成するために重要
- サンプルは調和的で美的に魅力的
- タグ（ジャンル、楽器など）に基づく条件付き生成が可能

### 3.4 音声認識

TIMITデータセットを使用して音声認識タスクを行いました。

結果:
- 生の音声から直接学習したモデルとしては最高の18.8 PER（音素誤り率）を達成

## 4. 結論

WaveNetは、音声波形レベルで直接動作する深層生成モデルです。自己回帰的で因果的なフィルターと希釈畳み込みを組み合わせることで、音声信号の長期的な時間依存性をモデル化することができます。

TTSタスクでは、主観的な自然さにおいて現在最高のTTSシステムを上回る性能を示しました。また、音楽音声のモデリングや音声認識においても非常に有望な結果を示しました。

これらの結果は、WaveNetが音声生成に依存する多くのアプリケーションに対して汎用的で柔軟なフレームワークを提供する可能性を示唆しています。
