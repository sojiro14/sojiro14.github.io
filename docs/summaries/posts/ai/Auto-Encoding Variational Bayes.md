---
title: Auto-Encoding Variational Bayes
date: 2022-12-10
comments: true
categories: [Statistics, Machine Learning]
---

# Auto-Encoding Variational Bayes
- <https://arxiv.org/abs/1312.6114>
- <https://arxiv.org/pdf/1312.6114>

---
## 1. はじめに

この論文は、Diederik P. KingmaとMax Wellingによって2013年に発表された「Auto-Encoding Variational Bayes」についての解説です。VAEは、深層学習と確率的推論を組み合わせた強力な生成モデルであり、現在も広く使用されています。

## 2. 問題設定

### 2.1 背景

- 連続潜在変数を持つ確率的モデルにおいて、効率的な推論と学習を行うことが課題
- 従来の変分推論手法では、解析的に解けない場合が多い
- 大規模データセットへの適用が困難

### 2.2 目的

1. パラメータθの効率的な近似最尤推定またはMAP推定
2. 観測値xが与えられた時の潜在変数zの効率的な近似事後推論
3. 変数xの効率的な近似周辺推論

## 3. 提案手法：Auto-Encoding Variational Bayes (AEVB)

### 3.1 基本的なアイデア

- 変分下限の再パラメータ化により、確率的勾配降下法で最適化可能な推定量を導出
- 認識モデル（エンコーダ）を用いて、効率的な近似事後推論を実現

### 3.2 変分下限の導出

変分下限L(θ, φ; x^(i))は以下のように表される：

```
L(θ, φ; x^(i)) = E[log p_θ(x^(i)|z)] - D_KL(q_φ(z|x^(i)) || p_θ(z))
```

ここで、
- p_θ(x|z)：生成モデル（デコーダ）
- q_φ(z|x)：近似事後分布（エンコーダ）
- p_θ(z)：潜在変数の事前分布

### 3.3 再パラメータ化トリック

q_φ(z|x)からのサンプリングを、補助的なノイズ変数εを用いて以下のように表現：

```
z = g_φ(ε, x) with ε ~ p(ε)
```

これにより、勾配の計算が可能になる。

### 3.4 SGVB（Stochastic Gradient Variational Bayes）推定量

変分下限の推定量：

```
L̃(θ, φ; x^(i)) ≈ 1/L * Σ[log p_θ(x^(i), z^(i,l)) - log q_φ(z^(i,l)|x^(i))]
```

ここで、z^(i,l) = g_φ(ε^(l), x^(i))、ε^(l) ~ p(ε)

## 4. 実装例：Variational Auto-Encoder

### 4.1 モデル構造

- エンコーダ（q_φ(z|x)）：多層パーセプトロン（MLP）
- デコーダ（p_θ(x|z)）：MLPまたはベルヌーイMLP
- 潜在変数の事前分布：標準正規分布

### 4.2 目的関数

```
L(θ, φ; x^(i)) ≈ 1/2 * Σ(1 + log((σ_j^(i))^2) - (μ_j^(i))^2 - (σ_j^(i))^2)
                  + 1/L * Σ[log p_θ(x^(i)|z^(i,l))]
```

ここで、z^(i,l) = μ^(i) + σ^(i) * ε^(l)、ε^(l) ~ N(0, I)

## 5. 実験結果

### 5.1 データセット

- MNIST（手書き数字）
- Frey Face（顔画像）

### 5.2 評価指標

- 変分下限
- 推定周辺尤度

### 5.3 比較手法

- Wake-Sleep アルゴリズム
- Monte Carlo EM

### 5.4 結果

![Figure 2: Comparison of AEVB to Wake-Sleep](https://github.com/user-attachments/assets/1af8bbab-60a6-4d25-9d50-18b4550b22bf)



- AEVBは他の手法よりも速く収束し、より良い解を得た
- 潜在変数の次元数を増やしても過学習は起こらなかった

## 6. 考察と今後の展望

### 6.1 VAEの利点

- 効率的な推論と学習が可能
- 大規模データセットに適用可能
- 幅広いモデルに応用可能

### 6.2 今後の研究方向

1. 深層ニューラルネットワークを用いた階層的生成アーキテクチャの学習
2. 時系列モデルへの応用
3. グローバルパラメータへのSGVBの適用
4. 教師あり学習への応用

## 7. 結論

VAEは、生成モデルの新しいパラダイムを提示し、効率的な推論と学習を可能にしました。理論的な裏付けと実験結果の両面から、このフレームワークの有効性が示されました。VAEは、深層学習と確率的推論の分野に大きな影響を与え、その後の多くの研究の基礎となっています。

---
# 高校生のためのVAE（Variational Auto-Encoder）解説

## 1. VAEって何？

VAE（Variational Auto-Encoder）は、コンピューターに新しい画像や音楽を作らせる方法の一つです。2013年に考え出された、とてもクールな技術です。

## 2. なぜVAEが必要なの？

1. コンピューターに「創造性」を持たせたい
2. 大量のデータから効率よく学習させたい
3. 新しいデータを生成する能力を持たせたい

## 3. VAEのしくみ

VAEは、次の2つの部分からできています：

1. **エンコーダ**：入力（例：画像）を「潜在空間」という特別な場所に変換します。
2. **デコーダ**：潜在空間から元の形（画像など）に戻します。

簡単に言うと、VAEは「圧縮→解凍」のようなものです。でも、普通の圧縮と違って、VAEは「意味」を理解しながら圧縮します。

## 4. どうやって学習するの？

VAEの学習は、次のような流れで行います：

1. 画像を入力する
2. エンコーダで潜在空間に変換する
3. デコーダで元の画像に戻す
4. 元の画像と比べて、どれくらい似ているか確認する
5. より似るように、少しずつエンコーダとデコーダを調整する

この過程を何度も繰り返すことで、VAEは徐々に上手になっていきます。

## 5. VAEの特徴

1. **確率的**: 少しランダム性があるので、毎回少し違う結果が出ます。
2. **連続的**: 潜在空間では、似たものが近くに配置されます。
3. **生成能力**: 新しいデータを作り出せます。

## 6. VAEで何ができるの？

1. **画像生成**: 実在しない人の顔や、架空の風景を作れます。
2. **画像編集**: 笑顔→悲しい顔、などの変換ができます。
3. **異常検知**: 普通じゃないものを見つけられます。
4. **データ圧縮**: 効率的にデータを保存できます。

## 7. 実験結果

研究者たちは、VAEを使って手書き数字（MNIST）や顔画像（Frey Face）のデータセットで実験しました。結果、VAEは他の方法より速く学習し、より良い結果を出しました。

## 8. まとめ

VAEは、コンピューターに「創造性」を持たせる強力な道具です。画像生成や編集、異常検知など、さまざまな分野で活用されています。まだ発展途上の技術ですが、将来はもっと驚くような使い方が見つかるかもしれません。

VAEを理解することで、人工知能がどのように「考え」、「創造」するのかについての洞察が得られます。これからのテクノロジーの発展に、VAEは大きな役割を果たすでしょう！
