---
title: Don't Make Your LLM an Evaluation Benchmark Cheater
date: 2023-11-03
comments: true
categories: [Computer Science, Computation and Language]
---

# Don't Make Your LLM an Evaluation Benchmark Cheater
- <https://arxiv.org/abs/2311.01964>
- <https://arxiv.org/pdf/2311.01964>

---
## 序論
本論文では、大規模言語モデル（LLM）の評価における不適切なベンチマークの使用とその影響について議論します。特に、評価セットに関連するデータがモデル訓練に使用される「ベンチマーク漏洩」の問題に焦点を当てます。

## 評価ベンチマークの問題
LLMの性能を評価するために、多くの高品質な評価ベンチマークが提案されています。しかし、これらのベンチマークの適切な使用と、公正なモデル比較に対する懸念が増しています。

## ベンチマーク漏洩の影響
ベンチマーク漏洩は、テストデータや関連データが訓練データに含まれる現象を指します。これにより、LLMの評価結果が不正に向上し、モデルの性能評価が信頼できなくなります。

## 実験と結果
実験では、異なる漏洩設定で複数のモデルを訓練し、評価しました。その結果、ベンチマーク漏洩が評価結果を不正に向上させることが確認されました。特に、小規模なモデルでも大規模なモデルを上回る結果を示すことがありました。

## 改善策
評価ベンチマークの適切な使用を促進するために、以下の改善策を提案します：
- データ汚染のチェックを実施
- 評価ベンチマークの多様なソースからの収集
- テストプロンプトの漏洩を避ける

## 結論
ベンチマーク漏洩の問題は、LLMの評価において重大なリスクをもたらします。適切な評価方法を確立し、公正な比較を実現するために、提案された改善策を採用することが重要です。
