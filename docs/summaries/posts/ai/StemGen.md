---
title: "StemGen: A music generation model that listens"
date: 2024-01-16
comments: true
categories: [Computer Science, Sound]
---

# StemGen: A music generation model that listens
- <https://arxiv.org/abs/2312.08723>
- <https://arxiv.org/pdf/2312.08723>

---

## StemGen: コンテキストを理解して音楽を生成するAIモデル

## 1. 論文の概要

この論文は、ByteDanceの研究チームが開発した「StemGen」という新しい音楽生成AIモデルについて解説しています。従来の音楽生成AIと異なり、このモデルは既存の音楽（コンテキスト）を「聴いて」、それに合わせた新しいパートを生成することができます。

### 主なポイント
- 既存の音楽コンテキストを理解して適切な応答を生成
- 非自己回帰的なTransformerベースのアーキテクチャを採用
- 音声品質は最新の文章条件付きモデルと同等
- 生成された音楽はコンテキストと高い一貫性を持つ

## 2. 従来の音楽生成AIとの違い

### 従来のモデル
- 抽象的な条件（テキスト説明やスタイルカテゴリ）から音楽を生成
- 完全なミックス済み音楽を出力
- 既存の音楽との相互作用が限定的

### StemGenの特徴
- 既存の音楽を入力として受け取る
- 個別のステム（楽器パートなど）を生成
- 音楽制作の実際のワークフローにより適合

## 3. モデルの仕組み

### トレーニングの方法

![トレーニングの概要図](https://github.com/user-attachments/assets/8b4d3aeb-e182-4a36-86b8-2b35a494cda0)

1. 音楽データをステム（個別パート）に分離
2. ランダムにN個のステムを選んでミックス（コンテキスト）を作成
3. 残りのステムから1つを選んでターゲットとする
4. コンテキストとターゲットのペアでモデルを学習

### アーキテクチャの特徴
- 音声をトークン化して処理
- 複数のオーディオチャンネルを単一のシーケンス要素に結合
- 非自己回帰的なTransformerモデルを使用
- 新しいトークン結合手法を導入

## 4. 技術的な革新点

### 1. 因果バイアス付き反復デコーディング
- シーケンスの早い要素から順にサンプリング
- より自然な音の遷移を実現
- 振幅の不自然な揺らぎを防止

### 2. マルチソース分類器フリーガイダンス
- 音声コンテキストと他の条件付け情報を独立して制御
- より強力なコンテキストとの整合性を実現
- 複数の条件付けソースに対して個別の重み付けが可能

## 5. 評価と結果

### 評価指標
1. Fr´echet Audio Distance (FAD)
   - 生成音声の品質を評価
   - VGGish埋め込みを使用

2. Music Information Retrieval Descriptor Distance (MIRDD)
   - ピッチ、リズム、構造などの音楽的特徴を評価
   - 複数のMIR記述子を使用

### 評価結果
- FADスコアは最新の文章条件付きモデルと同等
- マルチソース分類器フリーガイダンスの効果を確認
- 因果バイアスの導入により音質と音楽的整合性が向上
- 人間の演奏データでトレーニングしたモデルがより良い結果を示す

## 6. 実用性と応用

### 想定される用途
- 音楽制作における新しいパートの生成
- 既存の楽曲への追加パート作成
- プロデューサーや音楽家の創作支援

### 利点
- 既存のワークフローとの親和性が高い
- 音楽的なコンテキストを理解して適切な応答を生成
- 高品質な音声出力が可能

## 7. 結論と今後の展望

- ステムベースの音楽生成の新しいフレームワークを確立
- 音声品質と音楽的整合性の両面で高いパフォーマンスを実現
- 実際の音楽制作現場での活用が期待される

この研究は、AIを使った音楽生成の新しいアプローチを示すとともに、実際の音楽制作ワークフローにより適した方法を提案しています。既存の音楽との調和を保ちながら新しいパートを生成できる能力は、音楽制作の現場に大きな可能性をもたらすと考えられます。
