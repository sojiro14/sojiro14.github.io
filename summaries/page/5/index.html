
<!doctype html>
<html lang="ja" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://blog.sojiro.me/summaries/page/5/">
      
      
        <link rel="prev" href="../../../blog/archive/2014/">
      
      
        <link rel="next" href="../../category/artificial-intelligence/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Recent Posts - Sojiro's Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-ECN7E21ZM0"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-ECN7E21ZM0",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-ECN7E21ZM0",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Recent Posts - Sojiro's Blog" >
      
        <meta  property="og:description"  content="None" >
      
        <meta  property="og:image"  content="https://blog.sojiro.me/assets/images/social/summaries/page/5/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://blog.sojiro.me/summaries/page/5/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Recent Posts - Sojiro's Blog" >
      
        <meta  name="twitter:description"  content="None" >
      
        <meta  name="twitter:image"  content="https://blog.sojiro.me/assets/images/social/summaries/page/5/index.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#recent-posts" class="md-skip">
          コンテンツにスキップ
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="ヘッダー">
    <a href="../../.." title="Sojiro&#39;s Blog" class="md-header__button md-logo" aria-label="Sojiro's Blog" data-md-component="logo">
      
  <img src="../../../assets/images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sojiro's Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Recent Posts
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="検索" placeholder="検索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="検索">
        
        <button type="reset" class="md-search__icon md-icon" title="クリア" aria-label="クリア" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            検索を初期化
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="ナビゲーション" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Sojiro&#39;s Blog" class="md-nav__button md-logo" aria-label="Sojiro's Blog" data-md-component="logo">
      
  <img src="../../../assets/images/logo.png" alt="logo">

    </a>
    Sojiro's Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Recent Posts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2024/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2022/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2022
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2017/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2017
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2016/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2016
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2015/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2015
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2014/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2014
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/aws/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AWS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/anaconda/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anaconda
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/android-studio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Android Studio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/bigquery/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BigQuery
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/bower/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bower
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/cpan/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CPAN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/canvas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Canvas
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/chef/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chef
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/datastore/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Datastore
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/disqus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Disqus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/domain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Domain
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/erc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ERC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/ethereum/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ethereum
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gae/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GAE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gce/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gcp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gcs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/git/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Git
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/github/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GitHub
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/github-pages/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Github Pages
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/grunt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Grunt
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/html5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HTML5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/heroku/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Heroku
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/homebrew/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Homebrew
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/hubot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hubot
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/irc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    IRC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/json-schema/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    JSON Schema
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/java/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Java
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/liveportrait/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LivePortrait
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/mean/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MEAN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/mongodb/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MongoDB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/mysql/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MySQL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/nft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    NFT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/nodejs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Node.js
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/oop/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    OOP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/octopress/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Octopress
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/perl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Perl
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/repl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    REPL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/rvm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RVM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/redis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Redis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/reply/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reply
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/ruby/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ruby
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/ruby-on-rails/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ruby on Rails
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/shell/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shell
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/slack/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slack
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/task-queue/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Task Queue
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/vagrant/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vagrant
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/vim/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vim
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/vuepress/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VuePress
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/web/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Web
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/webrtc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    WebRTC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/wordpress/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    WordPress
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/yeoman/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Yeoman
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/npm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    npm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/revealjs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    reveal.js
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/screen/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    screen
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/yo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    yo
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Paper Summaries
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Paper Summaries
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
      
    
  
  
    <li class="md-nav__item">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="../../" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Recent Posts
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2024/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2023/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2023
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2022/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2022
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2021/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2021
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2020/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2020
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2019/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2019
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2018/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2018
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2017/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2017
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2016/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2016
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2015/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2015
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2014/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2014
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/1972/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1972
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/artificial-intelligence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Artificial Intelligence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/audio-and-speech-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Audio and Speech Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/call-center/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Call Center
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/computation-and-language/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computation and Language
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/computer-science/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computer Science
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/computer-vision-and-pattern-recognition/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computer Vision and Pattern Recognition
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/digital-libraries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Digital Libraries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/electrical-engineering-and-systems-science/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Electrical Engineering and Systems Science
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/emergence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/information-retrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Information Retrieval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/machine-learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Machine Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/reductionism/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reductionism
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/sound/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sound
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/speech-to-text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speech to text
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/statistics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Statistics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/synthetic-biology/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Synthetic Biology
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%82%B5%E3%83%83%E3%82%AB%E3%83%BC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    サッカー
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%BC%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    シミューレーションデータ
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%84/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    スポーツ
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%83%9E%E3%83%AB%E3%83%81%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    マルチエージェント
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E5%9F%BA%E7%9B%A4%E3%83%A2%E3%83%87%E3%83%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    基盤モデル
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E5%BB%BA%E7%AF%89%E7%9A%84%E6%BD%9C%E5%9C%A8%E4%BE%A1%E5%80%A4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    建築的潜在価値
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    強化学習
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    機械学習
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    深層学習
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E7%A4%BE%E4%BC%9A%E7%9A%84%E4%BE%A1%E5%80%A4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    社会的価値
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    言語モデル
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E9%AB%98%E7%B5%8C%E5%B9%B4%E8%B3%83%E8%B2%B8%E3%83%9E%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%B3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    高経年賃貸マンション
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目次">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="recent-posts">Recent Posts</h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-07-21 00:00:00+00:00">2020年7月21日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/sound/" class="md-meta__link">Sound</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="score-and-lyrics-free-singing-voice-generation"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/">Score and Lyrics-Free Singing Voice Generation</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1912.11747">https://arxiv.org/abs/1912.11747</a></li>
<li><a href="https://arxiv.org/pdf/1912.11747">https://arxiv.org/pdf/1912.11747</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#_1">歌詞とスコアを使わない歌声合成に関する研究解説</a></h3>
<h3 id="1"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#1">1. 研究の概要と目的</a></h3>
<p>この研究は、従来の歌声合成(SVS: Singing Voice Synthesis)とは異なるアプローチを提案しています。</p>
<p>従来のSVSは:
- 楽譜(音符の配列)と歌詞が必要
- それらに基づいて歌声を生成</p>
<p>一方、この研究が目指すのは:
- 楽譜も歌詞も使わない歌声生成
- 訓練時にも推論時にも不要
- より自由な歌声表現の実現</p>
<p>この新しいアプローチが必要な理由:
1. 人間の歌唱活動は楽譜に頼らないものも多い
   - 子供の自発的な歌唱
   - ハミング
   - ジャズボーカリストの即興演奏
2. より自由な音楽表現の可能性を広げる</p>
<h3 id="2-3"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#2-3">2. 提案される3つの歌声生成方式</a></h3>
<h4 id="21-free-singer"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#21-free-singer">2.1 フリーシンガー (Free Singer)</a></h4>
<ul>
<li>ランダムノイズのみを入力として歌声を生成</li>
<li>入浴中のハミングのような自由な歌唱を目指す</li>
<li>必ずしも良い歌声である必要はない</li>
</ul>
<h4 id="22-accompanied-singer"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#22-accompanied-singer">2.2 アカンパニードシンガー (Accompanied Singer)</a></h4>
<ul>
<li>伴奏音楽を入力として受け取る</li>
<li>伴奏に合わせて歌声を生成</li>
<li>カラオケのように、ただし歌詞なしで</li>
<li>伴奏のメロディーを単に真似るのではなく、調和する新しいメロディーを生成</li>
</ul>
<h4 id="23-solo-singer"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#23-solo-singer">2.3 ソロシンガー (Solo Singer)</a></h4>
<ul>
<li>フリーシンガーと同様にノイズを入力として受け取る</li>
<li>しかし、まず「内部アイデア」を生成</li>
<li>その「内部アイデア」に基づいて歌声を生成</li>
<li>例：コード進行を内部アイデアとして生成</li>
</ul>
<pre><code class="language-mermaid">graph LR
    A[Professional Audio] --&gt; B[Source Separation]
    B --&gt; C[Singing Voice]
    B --&gt; D[Accompaniment]
    C --&gt; E[Training Generator &amp; Discriminator]
    D --&gt; E

    F[New Accompaniment] --&gt; G[Trained Singer]
    G --&gt; H[Generated Voice]

    style A fill:#e0e0e0
    style B fill:#a0d8ef
    style C fill:#e0e0e0
    style D fill:#e0e0e0
    style E fill:#a0d8ef
    style F fill:#e0e0e0
    style G fill:#a0d8ef
    style H fill:#e0e0e0
</code></pre>
<h3 id="3"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#3">3. 技術的な課題</a></h3>
<p>研究では以下の3つの主要な課題が挙げられています：</p>
<ol>
<li>教師なし学習の必要性</li>
<li>音素やピッチのラベルなし</li>
<li>
<p>音声信号から直接学習する必要がある</p>
</li>
<li>
<p>データ収集の困難さ</p>
</li>
<li>ボーカル単独のトラックが必要</li>
<li>アカンパニードシンガーの場合は伴奏トラックも必要</li>
<li>
<p>公開されているデータが少ない</p>
</li>
<li>
<p>一対多の関係性</p>
</li>
<li>特にアカンパニードシンガーの場合</li>
<li>1つの伴奏に対して複数の妥当な歌唱パターンが存在</li>
<li>特定の歌声のみを正解とすることはできない</li>
</ol>
<h3 id="4"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#4">4. 提案手法</a></h3>
<h4 id="41"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#41">4.1 基本アーキテクチャ</a></h4>
<ul>
<li>GANベースのアーキテクチャを採用</li>
<li>メルスペクトログラムの生成を学習</li>
<li>生成されたメルスペクトログラムはボコーダーで音声に変換</li>
</ul>
<h4 id="42"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#42">4.2 モデルの特徴</a></h4>
<ul>
<li>GRU(Gated Recurrent Units)を使用</li>
<li>Dilated Convolutionsを採用</li>
<li>可変長の波形生成が可能</li>
<li>フレームごとのノイズを入力として使用</li>
</ul>
<h4 id="43"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#43">4.3 データ準備</a></h4>
<ul>
<li>ソース分離モデルを実装</li>
<li>プロの音楽録音から歌声と伴奏を分離</li>
<li>分離された音声トラックを訓練データとして使用</li>
</ul>
<h4 id="44"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#44">4.4 コード生成器</a></h4>
<p>ソロシンガーのために以下の機能を持つコード生成器を実装:
- 12のメジャーキーと12のマイナーキー対応
- 60〜240 BPMの10段階のテンポ
- 6種類の拍子記号
- 51種類のコードクオリティ(全612コード)</p>
<h3 id="5"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#5">5. 実験と評価</a></h3>
<h4 id="51"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#51">5.1 実装詳細</a></h4>
<ul>
<li>80次元のメルスペクトログラムを使用</li>
<li>WaveRNNボコーダーで音声生成</li>
<li>学習データ：</li>
<li>女性ジャズボーカル17.4時間</li>
<li>男性ジャズボーカル7.6時間</li>
<li>10秒のサブクリップに分割して使用</li>
</ul>
<h4 id="52"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#52">5.2 客観的評価指標</a></h4>
<p>以下の3つの指標で評価:
1. Vocalness (歌声らしさ)
2. Average pitch (平均ピッチ)
3. Singing-accompaniment matchness (歌声と伴奏の調和度)</p>
<h4 id="53"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#53">5.3 主観的評価</a></h4>
<p>ユーザースタディを2回実施:
1. 開発段階の異なるモデル間の比較
2. 既存の歌声合成システム(SinsyとSynthesizer V)との比較</p>
<h4 id="54"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#54">5.4 評価結果</a></h4>
<ul>
<li>音質面では改善の余地あり</li>
<li>人間らしさと感情表現では良好な結果</li>
<li>既存システムと比較して:</li>
<li>Synthesizer Vが全体的に最高評価</li>
<li>Sinsyとは表現力で近い評価</li>
<li>伴奏との調和度ではSinsyを上回る</li>
</ul>
<h3 id="6"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#6">6. 今後の展望</a></h3>
<p>研究チームは以下の方向性を示唆:
1. 音色と表現のコントロール機能の追加
2. 新しいネットワークアーキテクチャの検討
3. マルチスケール生成手法の導入
4. より細かな自己回帰モデルの検討</p>
<h3 id="7"><a class="toclink" href="../../2020/07/21/score-and-lyrics-free-singing-voice-generation/#7">7. 結論</a></h3>
<ul>
<li>楽譜と歌詞を使わない新しい歌声合成の可能性を示した</li>
<li>音質面では改善の余地があるものの、人間らしさと感情表現では良好な結果</li>
<li>計算創造性への貢献可能性を示唆</li>
<li>さらなる技術的改善の方向性を提示</li>
</ul>
<p>この研究は歌声合成の新しいアプローチを切り開き、より自由な音楽表現の可能性を広げる重要な一歩となっています。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-04-30 00:00:00+00:00">2020年4月30日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/electrical-engineering-and-systems-science/" class="md-meta__link">Electrical Engineering and Systems Science</a>, 
              <a href="../../category/audio-and-speech-processing/" class="md-meta__link">Audio and Speech Processing</a>, 
              <a href="../../category/sound/" class="md-meta__link">Sound</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約3分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="jukebox-a-generative-model-for-music"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/">Jukebox: A Generative Model for Music</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2005.00341">https://arxiv.org/abs/2005.00341</a></li>
<li><a href="https://arxiv.org/pdf/2005.00341">https://arxiv.org/pdf/2005.00341</a></li>
</ul>
<hr />
<h3 id="jukebox"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#jukebox">Jukebox: 音楽生成のための生成モデル</a></h3>
<h3 id="1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#1">1. 概要</a></h3>
<p>この論文は、OpenAIが開発した「Jukebox」という音楽生成AIモデルについて説明しています。Jukeboxは以下の特徴を持ちます：</p>
<ul>
<li>生の音声データから直接音楽を生成できる</li>
<li>歌詞に合わせて歌声を生成できる</li>
<li>アーティストや曲のジャンルを指定して生成できる</li>
<li>数分間の長さの一貫した音楽を生成可能</li>
</ul>
<h3 id="2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#2">2. 背景と課題</a></h3>
<h4 id="21"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#21">2.1 音楽生成の難しさ</a></h4>
<p>音楽生成には以下のような課題があります：</p>
<ol>
<li>音声データの膨大な情報量</li>
<li>4分間の音楽 = 約1000万のサンプル点</li>
<li>各サンプル点は16ビットの情報を持つ</li>
<li>
<p>画像生成と比べても非常に大きな情報量を扱う必要がある</p>
</li>
<li>
<p>音楽の多様な要素</p>
</li>
<li>メロディ、作曲、音色、人の声など</li>
<li>これらを統合的に生成する必要がある</li>
</ol>
<h3 id="3-jukebox"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#3-jukebox">3. Jukeboxのアーキテクチャ</a></h3>
<p>Jukeboxは以下の3つの主要コンポーネントで構成されています：</p>
<ol>
<li>VQ-VAE (Vector Quantized Variational AutoEncoder)</li>
<li>Prior モデル</li>
<li>Upsampler モデル</li>
</ol>
<h4 id="31-vq-vae"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#31-vq-vae">3.1 VQ-VAEの構造</a></h4>
<p><img alt="VQ-VAE structure" src="https://github.com/user-attachments/assets/8e0d40e6-1c60-4018-a6e0-6923ca2b752a" /></p>
<p>VQ-VAEは3つのレベルで音声を圧縮します：</p>
<ul>
<li>Bottom level: 8倍圧縮</li>
<li>Middle level: 32倍圧縮</li>
<li>Top level: 128倍圧縮</li>
</ul>
<p>各レベルは以下のコンポーネントを持ちます：
1. エンコーダー：音声を潜在表現に変換
2. ベクトル量子化：連続的な潜在表現を離散的なコードに変換
3. デコーダー：コードを音声に戻す</p>
<h4 id="32-priorupsampler"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#32-priorupsampler">3.2 PriorモデルとUpsampler</a></h4>
<p><img alt="Prior and Upsampler" src="https://github.com/user-attachments/assets/7860263b-b777-4426-a978-cc41f141a145" /></p>
<p>これらのモデルは以下の役割を果たします：</p>
<ol>
<li>Priorモデル</li>
<li>Top levelのコードを生成</li>
<li>
<p>アーティスト、ジャンル、歌詞などの条件付け情報を使用</p>
</li>
<li>
<p>Upsamplerモデル</p>
</li>
<li>上位レベルのコードから下位レベルのコードを生成</li>
<li>より細かい音楽の詳細を追加</li>
</ol>
<h3 id="4"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#4">4. 条件付け機能</a></h3>
<p>Jukeboxは以下の要素で音楽生成を制御できます：</p>
<ol>
<li>アーティストとジャンル</li>
<li>特定のアーティストのスタイルで生成</li>
<li>
<p>特定のジャンルの特徴を反映</p>
</li>
<li>
<p>歌詞</p>
</li>
<li>指定した歌詞に合わせて歌声を生成</li>
<li>
<p>歌詞のタイミングも自動的に調整</p>
</li>
<li>
<p>タイミング情報</p>
</li>
<li>曲の全体長</li>
<li>現在の位置</li>
<li>経過時間の割合</li>
</ol>
<h3 id="5"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#5">5. 実験結果</a></h3>
<h4 id="51"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#51">5.1 データセット</a></h4>
<ul>
<li>120万曲のデータセット</li>
<li>60万曲が英語の曲</li>
<li>歌詞とメタデータ（アーティスト、アルバム、ジャンル、年など）を含む</li>
</ul>
<h4 id="52"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#52">5.2 生成された音楽の特徴</a></h4>
<ol>
<li>一貫性</li>
<li>約24秒の範囲で強い一貫性を維持</li>
<li>
<p>ハーモニーやテクスチャの一貫性も保持</p>
</li>
<li>
<p>音楽性</p>
</li>
<li>自然な調和とメロディ</li>
<li>
<p>歌詞のリズムと自然な同期</p>
</li>
<li>
<p>多様性</p>
</li>
<li>異なるスタイルやジャンルの生成が可能</li>
<li>同じ条件でも異なる曲を生成可能</li>
</ol>
<h3 id="6"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#6">6. 今後の課題</a></h3>
<ol>
<li>音楽構造の改善</li>
<li>コーラスの繰り返しなど、長期的な構造の生成</li>
<li>
<p>より記憶に残るメロディの生成</p>
</li>
<li>
<p>音質の向上</p>
</li>
<li>ノイズの削減</li>
<li>
<p>より自然な音質の実現</p>
</li>
<li>
<p>生成速度の改善</p>
</li>
<li>現状1分の音楽生成に約1時間必要</li>
<li>より高速な生成が望ましい</li>
</ol>
<h3 id="7"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#7">7. 結論</a></h3>
<p>Jukeboxは以下の点で画期的な成果を達成しました：</p>
<ul>
<li>生の音声での音楽生成</li>
<li>複数分の一貫した音楽生成</li>
<li>歌詞、アーティスト、ジャンルの制御</li>
<li>実用的な品質の実現</li>
</ul>
<p>これらの成果は音楽生成AIの新たな可能性を示すものとなっています。</p>
<hr />
<h3 id="music-priorsupsamplers"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#music-priorsupsamplers">Music PriorsとUpsamplersの詳細解説</a></h3>
<h3 id="1_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#1_1">1. 基本構造と役割</a></h3>
<p>Music PriorsとUpsamplersは、VQ-VAEで圧縮された離散的なコード列から音楽を生成する重要なコンポーネントです。</p>
<p>生成プロセスは以下の確率モデルで表現されます：</p>
<pre><code>p(z) = p(z_top, z_middle, z_bottom)
     = p(z_top)p(z_middle|z_top)p(z_bottom|z_middle, z_top)
</code></pre>
<p>この数式は3つの要素で構成されています：
1. トップレベルPrior: p(z_top)
2. ミドルレベルUpsampler: p(z_middle|z_top)
3. ボトムレベルUpsampler: p(z_bottom|z_middle, z_top)</p>
<h3 id="2_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#2_1">2. モデルアーキテクチャ</a></h3>
<h4 id="21-transformer"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#21-transformer">2.1 Transformerの活用</a></h4>
<ul>
<li>Sparse Attention（疎な注意機構）を持つTransformerを使用</li>
<li>Scalable Transformerと呼ばれる簡略化されたバージョンを採用</li>
<li>実装がより容易で、スケーリングも改善</li>
</ul>
<h4 id="22-upsampler"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#22-upsampler">2.2 Upsamplerの条件付け機能</a></h4>
<p>上位レベルからの情報を取り込むため、以下の要素を使用：
1. 深層残差WaveNet
2. アップサンプリング用のストライド付き畳み込み
3. レイヤー正規化</p>
<p>これらの出力は、現在のレベルの埋め込みに追加の位置情報として加えられます。</p>
<h3 id="3"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#3">3. 条件付けメカニズム</a></h3>
<h4 id="31"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#31">3.1 アーティスト、ジャンル、タイミングの条件付け</a></h4>
<p>モデルは以下の情報を条件として受け取ります：
1. アーティストラベル
2. ジャンルラベル
3. タイミング信号
   - 曲の全体の長さ
   - 現在のサンプルの開始時間
   - 曲の経過割合</p>
<p>これにより：
- 予測のエントロピー（不確実性）が低減
- 特定のスタイルでの生成が可能
- 曲の構造に応じた生成が可能（イントロ、エンディングなど）</p>
<h4 id="32"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#32">3.2 歌詞による条件付け</a></h4>
<h5 id="lts-lyrics-to-singing"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#lts-lyrics-to-singing">歌詞と歌声の同期（LTS: Lyrics-to-singing）タスク</a></h5>
<p>課題：
- 歌詞のテキストのみを入力として使用
- タイミングや発声情報は含まない
- リード・バックボーカルと楽器の分離なし</p>
<p>対策：
1. 短いチャンク（24秒）での学習
2. Spleeterを使用して音声を抽出
3. NUS AutoLyricsAlignで歌詞の単語レベルの位置合わせを実施</p>
<h5 id="-"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#-">エンコーダー-デコーダーモデル</a></h5>
<p>特徴：
1. 歌詞エンコーダー
   - Transformerベース
   - 歌詞の自己回帰モデリング損失を使用
   - 最終層を歌詞の特徴として使用</p>
<ol>
<li>音楽デコーダー</li>
<li>エンコーダー-デコーダー注意層を追加</li>
<li>音楽トークンから歌詞トークンへの注意のみを許可</li>
<li>歌詞エンコーダーの最終層の活性化に注意を向ける</li>
</ol>
<h3 id="4_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#4_1">4. デコーダーの事前学習</a></h3>
<p>計算コストを削減するため：
1. 事前学習済みの無条件トップレベルPriorをデコーダーとして使用
2. モデルサージェリーを使用して歌詞エンコーダーを導入
3. 出力投影の重みを0で初期化
   - 追加層が初期化時に恒等関数として機能
   - エンコーダーの状態とパラメータに対する勾配は維持</p>
<h3 id="5_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#5_1">5. サンプリング手法</a></h3>
<h4 id="51_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#51_1">5.1 祖先サンプリング</a></h4>
<ol>
<li>トップレベルコードを一つずつ生成</li>
<li>条件付き情報を使用して制御</li>
<li>生成されたコードをVQ-VAEデコーダーで音声に変換</li>
</ol>
<h4 id="52_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#52_1">5.2 ウィンドウサンプリング</a></h4>
<ul>
<li>モデルのコンテキスト長より長い音楽を生成</li>
<li>前のコードの重複ウィンドウを使用して継続生成</li>
<li>品質と速度のトレードオフが可能</li>
</ul>
<h4 id="53"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#53">5.3 プライム付きサンプリング</a></h4>
<p>実際の曲の一部からスタートして新しい継続を生成：
1. 既存の音声をVQ-VAEでコードに変換
2. これらのコードを初期トークンとして使用
3. 新しい継続を生成</p>
<p>この詳細な構造により、Jukeboxは高品質で制御可能な音楽生成を実現しています。</p>
<hr />
<h3 id="jukebox_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#jukebox_1">Jukeboxが歌詞から音楽を生成できる仕組み</a></h3>
<h3 id="1_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#1_2">1. 基本的なアプローチ</a></h3>
<p>Jukeboxは「Lyrics-to-singing (LTS)」と呼ばれるタスクを実現しています。これは以下の要素を含みます：</p>
<ol>
<li>歌詞のテキスト入力</li>
<li>歌声の生成</li>
<li>音楽との同期</li>
</ol>
<h3 id="2_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#2_2">2. 主要な技術要素</a></h3>
<h4 id="21-"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#21-">2.1 エンコーダー-デコーダーアーキテクチャ</a></h4>
<ol>
<li>歌詞エンコーダー</li>
<li>Transformerベースのモデル</li>
<li>歌詞を意味のある特徴表現に変換</li>
<li>
<p>自己回帰的な学習で歌詞の文脈を理解</p>
</li>
<li>
<p>音楽デコーダー</p>
</li>
<li>歌詞の特徴を音楽生成に活用</li>
<li>エンコーダー-デコーダー注意機構で歌詞と音楽を結びつけ</li>
<li>歌詞のタイミングと音楽を同期</li>
</ol>
<h4 id="22"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#22">2.2 歌詞と音楽の同期システム</a></h4>
<ol>
<li>データの前処理</li>
<li>Spleeter: 音楽から歌声を抽出</li>
<li>NUS AutoLyricsAlign: 歌詞と歌声の位置合わせ</li>
<li>
<p>24秒の短いチャンクに分割して処理</p>
</li>
<li>
<p>注意機構による同期</p>
</li>
<li>デコーダーが歌詞の関連部分に注目</li>
<li>自然な歌唱タイミングを学習</li>
<li>強調すべき単語やフレーズを認識</li>
</ol>
<h3 id="3_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#3_1">3. 学習プロセス</a></h3>
<h4 id="31_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#31_1">3.1 データセット</a></h4>
<ul>
<li>60万曲の英語の楽曲</li>
<li>歌詞とメタデータを含む</li>
<li>アーティスト情報も活用</li>
</ul>
<h4 id="32_1"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#32_1">3.2 効率的な学習方法</a></h4>
<ol>
<li>デコーダーの事前学習</li>
<li>無条件の音楽生成モデルを先に学習</li>
<li>
<p>計算コストを削減</p>
</li>
<li>
<p>モデルサージェリー</p>
</li>
<li>事前学習済みモデルに歌詞処理能力を追加</li>
<li>段階的な能力の向上</li>
</ol>
<h3 id="4_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#4_2">4. 特徴と限界</a></h3>
<h4 id="41-jukebox"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#41-jukebox">4.1 Jukeboxの強み</a></h4>
<ol>
<li>自然な歌声生成</li>
<li>プロソディ（韻律）の適切な処理</li>
<li>
<p>言葉の強調の自然な表現</p>
</li>
<li>
<p>柔軟な制御</p>
</li>
<li>アーティストスタイルの反映</li>
<li>ジャンルに応じた歌い方の調整</li>
</ol>
<h4 id="42"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#42">4.2 現在の限界</a></h4>
<ol>
<li>処理速度</li>
<li>
<p>1分の音楽生成に約1時間必要</p>
</li>
<li>
<p>品質の制約</p>
</li>
<li>時々不明瞭な発音</li>
<li>一貫性の維持が難しい場合がある</li>
</ol>
<h3 id="5_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#5_2">5. なぜ実現可能なのか？</a></h3>
<p>Jukeboxが歌詞からの音楽生成を実現できる理由：</p>
<ol>
<li>大規模データでの学習</li>
<li>膨大な音楽-歌詞ペアからの学習</li>
<li>
<p>多様なパターンの理解</p>
</li>
<li>
<p>階層的な処理</p>
</li>
<li>トップレベル: 全体の構造</li>
<li>ミドルレベル: フレーズレベルの調整</li>
<li>
<p>ボトムレベル: 詳細な音声生成</p>
</li>
<li>
<p>複数の条件付け</p>
</li>
<li>歌詞</li>
<li>アーティストスタイル</li>
<li>ジャンル</li>
<li>
<p>タイミング
これらの要素が統合されることで、歌詞に基づいた自然な音楽生成が可能になっています。</p>
</li>
<li>
<p>注意機構の効果的な活用</p>
</li>
<li>歌詞と音楽の関連付け</li>
<li>適切なタイミングの学習</li>
<li>文脈の理解と反映</li>
</ol>
<p>これらの要素が組み合わさることで、Jukeboxは歌詞から意味のある音楽を生成することができます。</p>
<hr />
<h3 id="nus-autolyricsalign"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#nus-autolyricsalign">NUS AutoLyricsAlignの解説</a></h3>
<h3 id="1_3"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#1_3">1. 基本概要</a></h3>
<p>NUS AutoLyricsAlignは、音楽音声と歌詞のテキストを自動的に同期させるためのツールです。</p>
<p>主な目的：
- 音楽内の歌声と歌詞の単語を時間的に対応付ける
- どの単語がいつ歌われているかを特定する</p>
<h3 id="2_3"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#2_3">2. 重要性</a></h3>
<p>Jukeboxにおける役割：
1. 学習データの質向上
   - 歌詞と音声の正確な対応付け
   - より正確な歌声生成の学習が可能に</p>
<ol>
<li>前処理パイプライン
   <code>生の音楽 → Spleeter(歌声抽出) → NUS AutoLyricsAlign(歌詞同期)</code></li>
</ol>
<h3 id="3_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#3_2">3. 技術的な特徴</a></h3>
<h4 id="31_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#31_2">3.1 処理の流れ</a></h4>
<ol>
<li>音声からの特徴抽出</li>
<li>歌詞テキストの音素への変換</li>
<li>音声と音素の時間的アライメント</li>
<li>単語レベルのタイムスタンプ生成</li>
</ol>
<h4 id="32_2"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#32_2">3.2 利点</a></h4>
<ul>
<li>自動化された処理</li>
<li>単語レベルでの精密な同期</li>
<li>大規模データセットへの適用が可能</li>
</ul>
<h3 id="4_3"><a class="toclink" href="../../2020/04/30/jukebox-a-generative-model-for-music/#4_3">4. 実際の使用例</a></h3>
<p>Jukeboxでの活用：
1. 学習データの準備
   - 歌詞の時間情報の取得
   - 適切なチャンク分割のための情報提供</p>
<ol>
<li>生成時の制御</li>
<li>歌詞の自然なタイミング制御</li>
<li>プロソディの適切な反映</li>
</ol>
<p>注：論文では詳細な技術説明は提供されていませんが、音楽生成における重要なツールとして言及されています。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2020-02-14 00:00:00+00:00">2020年2月14日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/electrical-engineering-and-systems-science/" class="md-meta__link">Electrical Engineering and Systems Science</a>, 
              <a href="../../category/audio-and-speech-processing/" class="md-meta__link">Audio and Speech Processing</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/">Transformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2002.02562">https://arxiv.org/abs/2002.02562</a></li>
<li><a href="https://arxiv.org/pdf/2002.02562">https://arxiv.org/pdf/2002.02562</a></li>
</ul>
<hr />
<h3 id="transformer-transducer"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#transformer-transducer">Transformer Transducer: 音声認識のための新しいモデル</a></h3>
<h3 id="1"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#1">1. はじめに</a></h3>
<p>この論文では、Transformer Transducerと呼ばれる新しい音声認識モデルが提案されています。このモデルは、以下の特徴を持っています：</p>
<ol>
<li>Transformerエンコーダーを使用</li>
<li>RNN-T（Recurrent Neural Network Transducer）の損失関数を採用</li>
<li>ストリーミング（リアルタイム）音声認識に適用可能</li>
</ol>
<p>従来のRNN-Tモデルは、RNN（再帰型ニューラルネットワーク）を使用していましたが、この新しいモデルではTransformerを採用しています。</p>
<h3 id="2"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#2">2. モデルの構造</a></h3>
<p>Transformer Transducerの構造は以下の通りです：</p>
<p><img alt="RNN/Transformer Transducer architecture" src="https://github.com/user-attachments/assets/71ad9240-1e2b-4cd2-b4bb-44e0e606f673" /></p>
<p>主な構成要素は以下の3つです：</p>
<ol>
<li>音声エンコーダー（AudioEncoder）：音声入力を処理</li>
<li>ラベルエンコーダー（LabelEncoder）：過去の出力ラベルを処理</li>
<li>結合ネットワーク（Joint Network）：エンコーダーの出力を組み合わせて最終的な予測を生成</li>
</ol>
<p>従来のRNN-Tモデルでは、エンコーダーにLSTM（Long Short-Term Memory）を使用していましたが、Transformer Transducerでは両方のエンコーダーにTransformerを採用しています。</p>
<h3 id="3-transformer"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#3-transformer">3. Transformerの構造</a></h3>
<p>Transformerの各層は以下の2つのサブレイヤーで構成されています：</p>
<ol>
<li>マルチヘッド・アテンション層</li>
<li>フィードフォワード層</li>
</ol>
<p><img alt="Transformer encoder architecture" src="https://github.com/user-attachments/assets/390fa731-6ada-43eb-962f-894e798e3974" /></p>
<p>特徴：
- LayerNormを使用
- 残差接続を採用
- ドロップアウトで過学習を防止
- 相対位置エンコーディングを使用</p>
<h3 id="4"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#4">4. ストリーミング音声認識への適用</a></h3>
<p>Transformer Transducerは、ストリーミング（リアルタイム）音声認識にも適用できるように設計されています。そのために、以下の工夫がなされています：</p>
<ol>
<li>音声エンコーダーの注意を過去の限られたフレームに制限</li>
<li>ラベルエンコーダーの注意を過去の限られたラベルに制限</li>
</ol>
<p>これにより、モデルの計算量を一定に保ちつつ、リアルタイムでの音声認識が可能になります。</p>
<h3 id="5"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#5">5. 実験と結果</a></h3>
<h4 id="51"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#51">5.1 データセット</a></h4>
<p>実験には、LibriSpeechデータセットを使用しました：
- 970時間の音声データと対応するテキスト転写
- 追加の8億単語のテキストデータ</p>
<h4 id="52"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#52">5.2 モデルの詳細</a></h4>
<ul>
<li>音声エンコーダー：18層</li>
<li>ラベルエンコーダー：2層</li>
<li>出力単位：グラフェーム（文字単位）</li>
</ul>
<h4 id="53"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#53">5.3 主な結果</a></h4>
<ol>
<li>Transformer Transducerは、LSTMベースのRNN-Tモデルよりも高い精度を達成</li>
<li>全注意（full attention）モデルは、LibriSpeechベンチマークで最高精度を記録</li>
<li>限定的な注意（limited attention）モデルでも、ストリーミング音声認識に適した性能を実現</li>
</ol>
<p>具体的な結果は以下の表の通りです：</p>
<table>
<thead>
<tr>
<th>モデル</th>
<th>パラメータ数</th>
<th>WER (%) (clean / other)</th>
</tr>
</thead>
<tbody>
<tr>
<td>FullAttn T-T</td>
<td>139M</td>
<td>2.4 / 5.6</td>
</tr>
<tr>
<td>BiLSTM RNN-T</td>
<td>130M</td>
<td>3.2 / 7.8</td>
</tr>
</tbody>
</table>
<h4 id="54"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#54">5.4 コンテキスト制限の影響</a></h4>
<p>音声エンコーダーの左右のコンテキスト（注意を向ける範囲）を制限した場合の影響も調査されました。主な発見：</p>
<ol>
<li>左コンテキストを増やすほど性能が向上</li>
<li>右コンテキスト（未来のフレーム）を少し見ることで、全注意モデルとの性能差を縮小可能</li>
<li>ラベルエンコーダーは、非常に限られた左コンテキストでも十分な性能を発揮</li>
</ol>
<h3 id="6"><a class="toclink" href="../../2020/02/14/transformer-transducer-a-streamable-speech-recognition-model-with-transformer-encoders-and-rnn-t-loss/#6">6. 結論</a></h3>
<p>Transformer Transducerは以下の利点を持つ新しい音声認識モデルです：</p>
<ol>
<li>高い認識精度</li>
<li>ストリーミング音声認識への適用が可能</li>
<li>LSTMベースのモデルよりも高速に学習可能</li>
<li>精度と遅延のトレードオフを柔軟に調整可能</li>
</ol>
<p>この研究は、Transformerベースのモデルを音声認識タスクに効果的に適用できることを示し、今後の音声認識技術の発展に大きく貢献する可能性があります。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2019-11-20 00:00:00+00:00">2019年11月20日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="fastspeech-fast-robust-and-controllable-text-to-speech"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/">FastSpeech: Fast, Robust and Controllable Text to Speech</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1905.09263">https://arxiv.org/abs/1905.09263</a></li>
<li><a href="https://arxiv.org/pdf/1905.09263">https://arxiv.org/pdf/1905.09263</a></li>
</ul>
<hr />
<h3 id="fastspeech-text-to-speech"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#fastspeech-text-to-speech">FastSpeech: 高速で堅牢な制御可能なText-to-Speechシステム</a></h3>
<h3 id="1"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#1">1. はじめに</a></h3>
<p>近年、ディープラーニングを用いたエンドツーエンドのText-to-Speech (TTS)システムが大きく進歩し、合成音声の品質が向上しています。しかし、既存のシステムには以下のような課題があります：</p>
<ol>
<li>推論速度が遅い</li>
<li>合成音声の安定性が低い（単語の飛ばしや繰り返しが発生）</li>
<li>音声の速度や韻律のコントロールが難しい</li>
</ol>
<p>この論文では、これらの課題を解決する新しいTTSモデル「FastSpeech」を提案しています。</p>
<h3 id="2-fastspeech"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#2-fastspeech">2. FastSpeechの特徴</a></h3>
<p>FastSpeechは以下の特徴を持つ新しいTTSモデルです：</p>
<ol>
<li>フィードフォワードネットワークを使用し、並列でメルスペクトログラムを生成</li>
<li>音素の持続時間を予測し、それに基づいて音声の長さを調整</li>
<li>教師モデルから知識を蒸留して学習を行う</li>
</ol>
<p>これらの特徴により、高速で安定した音声合成が可能になり、さらに音声の速度や韻律をコントロールすることができます。</p>
<h3 id="3"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#3">3. モデルアーキテクチャ</a></h3>
<p>FastSpeechのモデルアーキテクチャは以下の主要な要素で構成されています：</p>
<ol>
<li>Feed-Forward Transformer (FFT)</li>
<li>Length Regulator</li>
<li>Duration Predictor</li>
</ol>
<h4 id="31-feed-forward-transformer-fft"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#31-feed-forward-transformer-fft">3.1 Feed-Forward Transformer (FFT)</a></h4>
<p>FFTは、Transformerのself-attentionメカニズムと1D畳み込みネットワークを組み合わせた構造です。音素側とメルスペクトログラム側にそれぞれN個のFFTブロックがスタックされています。</p>
<p><img alt="FFT Architecture" src="https://github.com/user-attachments/assets/97878452-e6ad-457a-ab5c-1d16d0d6e6d2" /></p>
<h4 id="32-length-regulator"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#32-length-regulator">3.2 Length Regulator</a></h4>
<p>Length Regulatorは、音素シーケンスとメルスペクトログラムシーケンスの長さの不一致を解決するためのコンポーネントです。各音素の持続時間に基づいて、音素の隠れ状態を拡張します。</p>
<h4 id="33-duration-predictor"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#33-duration-predictor">3.3 Duration Predictor</a></h4>
<p>Duration Predictorは、各音素の持続時間を予測するためのコンポーネントです。2層の1D畳み込みネットワークで構成されています。</p>
<h3 id="4"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#4">4. 学習方法</a></h3>
<p>FastSpeechの学習は以下の手順で行われます：</p>
<ol>
<li>自己回帰的なTransformer TTSモデルを教師モデルとして学習</li>
<li>教師モデルから音素の持続時間を抽出</li>
<li>シーケンスレベルの知識蒸留を用いてFastSpeechを学習</li>
</ol>
<h3 id="5"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#5">5. 実験結果</a></h3>
<p>LJSpeechデータセットを用いて実験を行い、以下の結果が得られました：</p>
<h4 id="51"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#51">5.1 音声品質</a></h4>
<p>Mean Opinion Score (MOS) 評価では、FastSpeechは既存の自己回帰モデルとほぼ同等の品質を達成しました。</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>MOS</th>
</tr>
</thead>
<tbody>
<tr>
<td>GT</td>
<td>4.41 ± 0.08</td>
</tr>
<tr>
<td>GT (Mel + WaveGlow)</td>
<td>4.00 ± 0.09</td>
</tr>
<tr>
<td>Tacotron 2 (Mel + WaveGlow)</td>
<td>3.86 ± 0.09</td>
</tr>
<tr>
<td>Transformer TTS (Mel + WaveGlow)</td>
<td>3.88 ± 0.09</td>
</tr>
<tr>
<td>FastSpeech (Mel + WaveGlow)</td>
<td>3.84 ± 0.08</td>
</tr>
</tbody>
</table>
<h4 id="52"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#52">5.2 推論速度</a></h4>
<p>FastSpeechは、メルスペクトログラム生成を269.40倍、エンドツーエンドの音声合成を38.30倍高速化しました。</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Latency (s)</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transformer TTS (Mel)</td>
<td>6.735 ± 3.969</td>
<td>/</td>
</tr>
<tr>
<td>FastSpeech (Mel)</td>
<td>0.025 ± 0.005</td>
<td>269.40×</td>
</tr>
<tr>
<td>Transformer TTS (Mel + WaveGlow)</td>
<td>6.895 ± 3.969</td>
<td>/</td>
</tr>
<tr>
<td>FastSpeech (Mel + WaveGlow)</td>
<td>0.180 ± 0.078</td>
<td>38.30×</td>
</tr>
</tbody>
</table>
<h4 id="53"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#53">5.3 堅牢性</a></h4>
<p>特に難しい50文に対して、FastSpeechは単語の飛ばしや繰り返しの問題をほぼ完全に解消しました。</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Repeats</th>
<th>Skips</th>
<th>Error Sentences</th>
<th>Error Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tacotron 2</td>
<td>4</td>
<td>11</td>
<td>12</td>
<td>24%</td>
</tr>
<tr>
<td>Transformer TTS</td>
<td>7</td>
<td>15</td>
<td>17</td>
<td>34%</td>
</tr>
<tr>
<td>FastSpeech</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0%</td>
</tr>
</tbody>
</table>
<h4 id="54"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#54">5.4 制御性</a></h4>
<p>FastSpeechは、音声の速度を0.5倍から1.5倍まで滑らかに調整でき、さらに単語間の休止を追加することで韻律の一部を制御できることが示されました。</p>
<p><img alt="Voice Speed Control" src="https://github.com/user-attachments/assets/a6eec4e7-7ad4-4a94-89c4-39a6202dd9f5" /></p>
<h3 id="6"><a class="toclink" href="../../2019/11/20/fastspeech-fast-robust-and-controllable-text-to-speech/#6">6. まとめと今後の課題</a></h3>
<p>FastSpeechは、高速で堅牢、かつ制御可能なTTSシステムを実現しました。今後の課題として以下が挙げられています：</p>
<ol>
<li>合成音声の品質のさらなる向上</li>
<li>多言語・多話者への対応</li>
<li>並列ニューラルボコーダーとの統合による完全なエンドツーエンドかつ並列なシステムの構築</li>
</ol>
<p>FastSpeechは、TTSの実用化に向けて大きな一歩を踏み出した革新的なモデルと言えるでしょう。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2019-05-15 00:00:00+00:00">2019年5月15日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/sound/" class="md-meta__link">Sound</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/">Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1809.07454">https://arxiv.org/abs/1809.07454</a></li>
<li><a href="https://arxiv.org/pdf/1809.07454">https://arxiv.org/pdf/1809.07454</a></li>
</ul>
<hr />
<h3 id="1"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#1">1. はじめに</a></h3>
<h4 id="11"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#11">1.1 研究の背景</a></h4>
<p>音声分離は、複数の話者が同時に話している音声から、個々の話者の音声を分離する技術です。これは、音声認識や補聴器などの実世界の音声処理技術にとって非常に重要な課題です。</p>
<p>これまでの音声分離手法の多くは、音声信号の時間-周波数(T-F)表現、つまりスペクトログラムを用いていました。しかし、この方法にはいくつかの問題点がありました：</p>
<ol>
<li>信号の位相と振幅が分離されてしまう</li>
<li>音声分離に最適でない可能性がある</li>
<li>スペクトログラム計算に時間がかかり、遅延が大きい</li>
</ol>
<h4 id="12-conv-tasnet"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#12-conv-tasnet">1.2 Conv-TasNetの提案</a></h4>
<p>著者らは、これらの問題を解決するために、完全畳み込み型の時間領域音声分離ネットワーク(Conv-TasNet)を提案しました。Conv-TasNetは以下の特徴を持ちます：</p>
<ul>
<li>時間領域で直接音声を分離</li>
<li>線形エンコーダを使用して音声波形の最適な表現を生成</li>
<li>時間畳み込みネットワーク(TCN)を使用して分離マスクを生成</li>
<li>線形デコーダを使用して波形を再構成</li>
</ul>
<h3 id="2-conv-tasnet"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#2-conv-tasnet">2. Conv-TasNetの構造</a></h3>
<p>Conv-TasNetは主に3つの部分から構成されています：</p>
<ol>
<li>エンコーダ</li>
<li>分離モジュール</li>
<li>デコーダ</li>
</ol>
<p>以下の図はConv-TasNetの全体構造を示しています：</p>
<p><img alt="Conv-TasNet structure" src="https://github.com/user-attachments/assets/1504767d-ecb9-4e4f-934f-da05ce84d55c" /></p>
<h4 id="21"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#21">2.1 エンコーダ</a></h4>
<p>エンコーダは入力波形を短いセグメントに分割し、各セグメントを高次元の表現に変換します。この過程は以下の式で表されます：</p>
<pre><code>w = H(xU)
</code></pre>
<p>ここで、xは入力セグメント、Uはエンコーダの基底関数、H(・)は非線形関数（オプション）です。</p>
<h4 id="22"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#22">2.2 分離モジュール</a></h4>
<p>分離モジュールは時間畳み込みネットワーク(TCN)を使用しています。TCNは以下の特徴を持ちます：</p>
<ul>
<li>拡張畳み込みを使用して長期依存性をモデル化</li>
<li>スキップ接続とresidual接続を使用</li>
<li>深さ方向分離可能畳み込みを使用してパラメータ数を削減</li>
</ul>
<p>分離モジュールは各話者のマスクを生成します。</p>
<h4 id="23"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#23">2.3 デコーダ</a></h4>
<p>デコーダはマスクされたエンコーダ出力を元の波形に戻す役割を果たします。この過程は以下の式で表されます：</p>
<pre><code>s_hat = d_i V
</code></pre>
<p>ここで、d_iはi番目の話者のマスクされた表現、Vはデコーダの基底関数です。</p>
<h3 id="3"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#3">3. 実験結果</a></h3>
<h4 id="31"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#31">3.1 データセット</a></h4>
<p>WSJ0-2mixとWSJ0-3mixデータセットを使用して、2話者および3話者の音声分離タスクで評価を行いました。</p>
<h4 id="32"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#32">3.2 性能比較</a></h4>
<p>Conv-TasNetは以下の点で優れた性能を示しました：</p>
<ul>
<li>従来のSTFT（短時間フーリエ変換）ベースの手法を大きく上回る性能</li>
<li>理想的な時間-周波数マスク（IBM, IRM, WFM）よりも高い性能</li>
<li>より小さいモデルサイズと短い遅延時間</li>
</ul>
<p>以下の表は、WSJ0-2mixデータセットにおける他の手法との比較結果を示しています：</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Model size</th>
<th>SI-SNRi (dB)</th>
<th>SDRi (dB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>DPCL++</td>
<td>13.6M</td>
<td>10.8</td>
<td>-</td>
</tr>
<tr>
<td>uPIT-BLSTM-ST</td>
<td>92.7M</td>
<td>-</td>
<td>10.0</td>
</tr>
<tr>
<td>Conv-TasNet-gLN</td>
<td>5.1M</td>
<td>15.3</td>
<td>15.6</td>
</tr>
</tbody>
</table>
<h4 id="33"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#33">3.3 主観評価</a></h4>
<p>人間の聴取者による主観評価（MOS: Mean Opinion Score）でも、Conv-TasNetは理想的な比率マスク（IRM）を上回る性能を示しました。</p>
<h3 id="4"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#4">4. 考察</a></h3>
<p>Conv-TasNetの優れた性能の理由として、以下の点が挙げられています：</p>
<ol>
<li>時間領域での直接的な分離により、位相の問題を回避</li>
<li>データ駆動型の表現学習により、音声分離に最適化された特徴を獲得</li>
<li>TCNの使用により、長期依存性を効率的にモデル化</li>
</ol>
<p>また、学習されたエンコーダ/デコーダの基底関数の分析から、以下の興味深い特徴が明らかになりました：</p>
<ul>
<li>低周波数帯域に多くのフィルタが集中（人間の聴覚系に類似）</li>
<li>位相情報の明示的な表現</li>
</ul>
<h3 id="5"><a class="toclink" href="../../2019/05/15/conv-tasnet-surpassing-ideal-time-frequency-magnitude-masking-for-speech-separation/#5">5. 結論</a></h3>
<p>Conv-TasNetは音声分離タスクにおいて従来手法を大きく上回る性能を示し、実世界の音声処理アプリケーションへの応用が期待されます。しかし、長期的な話者追跡や雑音・残響環境への対応など、さらなる研究課題も残されています。</p>
<p>この研究は、時間領域での音声分離の可能性を示し、今後の音声処理技術の発展に大きな影響を与えると考えられます。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2018-02-16 00:00:00+00:00">2018年2月16日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1712.05884">https://arxiv.org/abs/1712.05884</a></li>
<li><a href="https://arxiv.org/pdf/1712.05884">https://arxiv.org/pdf/1712.05884</a></li>
</ul>
<hr />
<h3 id="tacotron-2"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#tacotron-2">Tacotron 2: 高品質な音声合成システム</a></h3>
<h3 id="1"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#1">1. はじめに</a></h3>
<p>この論文は、Googleが開発した「Tacotron 2」という音声合成システムについて説明しています。Tacotron 2は、テキストから直接、非常に自然な音声を生成することができます。</p>
<p>従来の音声合成システムと比較して、Tacotron 2には以下のような特徴があります：</p>
<ol>
<li>完全にニューラルネットワークベース</li>
<li>複雑な特徴エンジニアリングを必要としない</li>
<li>人間の声に近い高品質な音声を生成</li>
</ol>
<h3 id="2"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#2">2. システムの構成</a></h3>
<p>Tacotron 2は主に2つの部分から構成されています：</p>
<ol>
<li>スペクトログラム予測ネットワーク</li>
<li>修正版WaveNet（音声波形生成器）</li>
</ol>
<p><img alt="Tacotron 2 Architecture" src="https://github.com/user-attachments/assets/1a98fc86-7c9b-4844-969d-8d6c65963cad" /></p>
<h4 id="21"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#21">2.1 スペクトログラム予測ネットワーク</a></h4>
<p>このネットワークは、入力されたテキスト（文字列）から、メルスペクトログラムと呼ばれる音声の特徴量を予測します。主な特徴は以下の通りです：</p>
<ul>
<li>エンコーダ・デコーダ構造を持つ再帰型ニューラルネットワーク</li>
<li>アテンション機構を使用</li>
<li>文字列を入力として受け取り、メルスペクトログラムのフレームを順次出力</li>
</ul>
<h4 id="22-wavenet"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#22-wavenet">2.2 修正版WaveNet</a></h4>
<p>WaveNetは、DeepMindが開発した音声波形生成モデルです。Tacotron 2では、このWaveNetを以下のように修正して使用しています：</p>
<ul>
<li>予測されたメルスペクトログラムを条件として、時間領域の波形サンプルを生成</li>
<li>30層の畳み込みレイヤーを使用</li>
<li>出力として、10個のロジスティック分布の混合を使用</li>
</ul>
<h3 id="3"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#3">3. 学習プロセス</a></h3>
<p>Tacotron 2の学習は2段階で行われます：</p>
<ol>
<li>スペクトログラム予測ネットワークの学習</li>
<li>修正版WaveNetの学習（予測されたスペクトログラムを使用）</li>
</ol>
<p>学習データには、単一の女性話者による約24.6時間の音声データを使用しています。</p>
<h3 id="4"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#4">4. 評価結果</a></h3>
<p>Tacotron 2の性能を評価するために、以下の実験が行われました：</p>
<ol>
<li>平均オピニオン評点（MOS）による評価</li>
<li>グラウンドトゥルース（実際の人間の声）との比較</li>
<li>ニュース見出しを用いた汎化性能の評価</li>
</ol>
<p>結果として、Tacotron 2は他のTTSシステムを大きく上回り、グラウンドトゥルースに匹敵するMOSスコアを達成しました。</p>
<p><img alt="MOS Comparison" src="https://github.com/user-attachments/assets/2c0ca0d7-ae79-4879-88f5-a613c30d3ff6" /></p>
<h3 id="5"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#5">5. アブレーション実験</a></h3>
<p>論文では、システムの各コンポーネントの重要性を確認するために、いくつかのアブレーション実験が行われています：</p>
<ol>
<li>予測特徴 vs グラウンドトゥルース特徴</li>
<li>リニアスペクトログラム vs メルスペクトログラム</li>
<li>ポストプロセッシングネットワークの効果</li>
<li>WaveNetの簡略化</li>
</ol>
<p>これらの実験により、各コンポーネントの役割や、システムの設計選択の妥当性が確認されました。</p>
<h3 id="6"><a class="toclink" href="../../2018/02/16/natural-tts-synthesis-by-conditioning-wavenet-on-mel-spectrogram-predictions/#6">6. 結論</a></h3>
<p>Tacotron 2は、完全にニューラルネットワークベースのTTSシステムとして、以下の特徴を持つことが示されました：</p>
<ul>
<li>Tacotronレベルのプロソディ（韻律）</li>
<li>WaveNetレベルの音質</li>
<li>複雑な特徴エンジニアリングを必要としない</li>
<li>人間の音声に近い高品質な合成音声の生成</li>
</ul>
<p>この研究は、エンド・ツー・エンドの音声合成システムの可能性を示し、将来的なTTS技術の発展に大きな影響を与えると考えられます。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2017-12-25 00:00:00+00:00">2017年12月25日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="improved-training-of-wasserstein-gans"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/">Improved Training of Wasserstein GANs</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1704.00028">https://arxiv.org/abs/1704.00028</a></li>
<li><a href="https://arxiv.org/pdf/1704.00028">https://arxiv.org/pdf/1704.00028</a></li>
</ul>
<hr />
<h3 id="wasserstein-gan"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#wasserstein-gan">Wasserstein GANの改良：勾配ペナルティの導入</a></h3>
<h3 id="1"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#1">1. はじめに</a></h3>
<p>この論文は、Generative Adversarial Networks (GANs)の一種であるWasserstein GAN (WGAN)の改良版を提案しています。従来のWGANの問題点を指摘し、新しい手法を導入することで、より安定した学習と高品質な生成結果を実現しています。</p>
<h3 id="2-ganwgan"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#2-ganwgan">2. 背景：GANとWGAN</a></h3>
<h4 id="21-gan"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#21-gan">2.1 GANの基本概念</a></h4>
<ul>
<li>生成器(Generator)と識別器(Discriminator)の2つのネットワークが対立しながら学習</li>
<li>学習が不安定になりやすい問題がある</li>
</ul>
<h4 id="22-wgan"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#22-wgan">2.2 WGANの特徴</a></h4>
<ul>
<li>Wasserstein距離を用いてGANを改良</li>
<li>識別器（批評器と呼ばれる）にLipschitz制約を課す</li>
<li>重みクリッピングを使用してLipschitz制約を実現</li>
</ul>
<h3 id="3"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#3">3. 問題点：重みクリッピングの限界</a></h3>
<p>著者らは、WGANで使用される重みクリッピングに以下の問題があると指摘しています：</p>
<ol>
<li>容量の不十分な利用</li>
<li>勾配の消失または爆発</li>
</ol>
<p>これらの問題を示すために、著者らはいくつかの実験を行いました。</p>
<p><img alt="Figure 1: 重みクリッピングと勾配ペナルティの比較" src="https://github.com/user-attachments/assets/e49c6582-f82a-4909-b42c-c12d6b193573" /></p>
<h3 id="4"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#4">4. 提案手法：勾配ペナルティ</a></h3>
<p>著者らは、重みクリッピングの代わりに「勾配ペナルティ」を導入することを提案しています。</p>
<h4 id="41"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#41">4.1 勾配ペナルティの定義</a></h4>
<p>新しい目的関数は以下のようになります：</p>
<pre><code>L = E[D(x̃)] - E[D(x)] + λ * E[(||∇D(x̂)||_2 - 1)^2]
</code></pre>
<p>ここで、x̂はデータ分布と生成分布の間の直線上からランダムにサンプリングされたポイントです。</p>
<h4 id="42"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#42">4.2 勾配ペナルティの特徴</a></h4>
<ul>
<li>Lipschitz制約をソフトに実現</li>
<li>バッチ正規化を使用しない</li>
<li>ペナルティ係数λ=10を使用</li>
</ul>
<h3 id="5"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#5">5. 実験結果</a></h3>
<p>著者らは、提案手法の有効性を示すためにいくつかの実験を行いました。</p>
<h4 id="51"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#51">5.1 多様なアーキテクチャでの学習</a></h4>
<p>200種類のランダムなアーキテクチャを生成し、従来のGANとWGAN-GPで学習を行いました。結果として、WGAN-GPの方が多くのアーキテクチャで成功しました。</p>
<h4 id="52-lsun"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#52-lsun">5.2 LSUN寝室データセットでの実験</a></h4>
<p>6種類の異なるアーキテクチャを用いて、LSUN寝室データセットで学習を行いました。WGAN-GPのみがすべてのアーキテクチャで安定した学習を実現しました。</p>
<h4 id="53-cifar-10"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#53-cifar-10">5.3 CIFAR-10での性能評価</a></h4>
<p>CIFAR-10データセットを用いて、Inception scoreを計算し、他の手法と比較しました。WGAN-GPは教師なし学習の中で最高のスコアを達成しました。</p>
<h4 id="54"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#54">5.4 離散データの生成</a></h4>
<p>文字レベルの言語モデルを学習させ、WGAN-GPが離散データの生成にも適用可能であることを示しました。</p>
<h3 id="6"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#6">6. 考察</a></h3>
<ul>
<li>WGAN-GPは、多様なアーキテクチャと様々なタスクで安定した学習を実現</li>
<li>高品質なサンプル生成が可能</li>
<li>学習の進行を損失関数の値で監視可能</li>
</ul>
<h3 id="7"><a class="toclink" href="../../2017/12/25/improved-training-of-wasserstein-gans/#7">7. 結論</a></h3>
<p>WGAN-GPは、従来のWGANの問題点を解決し、より安定した学習と高品質な生成を実現する手法です。様々なタスクやアーキテクチャに適用可能であり、GANの研究に新たな可能性を開きました。</p>
<p>この改良により、GANの応用範囲がさらに広がることが期待されます。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2017-08-05 00:00:00+00:00">2017年8月5日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/statistics/" class="md-meta__link">Statistics</a>, 
              <a href="../../category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約3分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="categorical-reparameterization-with-gumbel-softmax"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/">Categorical Reparameterization with Gumbel-Softmax</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1611.01144">https://arxiv.org/abs/1611.01144</a></li>
<li><a href="https://arxiv.org/pdf/1611.01144">https://arxiv.org/pdf/1611.01144</a></li>
</ul>
<hr />
<h3 id="gumbel-softmax"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#gumbel-softmax">Gumbel-Softmaxによるカテゴリカル再パラメータ化</a></h3>
<h3 id="1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#1">1. 研究の背景と目的</a></h3>
<h4 id="11"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#11">1.1 離散変数の重要性と課題</a></h4>
<p>現代の機械学習、特に深層学習において、離散的な構造を持つデータを扱うことは非常に重要です。例えば:</p>
<ul>
<li>言語モデリング</li>
<li>注意機構</li>
<li>強化学習</li>
</ul>
<p>これらの分野では、カテゴリカル変数（複数の選択肢から1つを選ぶ変数）が頻繁に使用されます。</p>
<p>しかし、カテゴリカル変数を含む確率的ニューラルネットワークの学習には大きな課題があります。通常のバックプロパゲーション（誤差逆伝播法）が使えないのです。</p>
<h4 id="12"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#12">1.2 研究の目的</a></h4>
<p>この論文の主な目的は、カテゴリカル変数を効率的に学習するための新しい手法を提案することです。具体的には:</p>
<ol>
<li>Gumbel-Softmax分布という新しい分布を導入</li>
<li>この分布を使った勾配推定器の提案</li>
<li>提案手法の有効性を実験で示す</li>
</ol>
<h3 id="2-gumbel-softmax"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#2-gumbel-softmax">2. Gumbel-Softmax分布</a></h3>
<h4 id="21"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#21">2.1 定義</a></h4>
<p>Gumbel-Softmax分布は、カテゴリカル分布を連続的に近似する分布です。数式で表すと：</p>
<pre><code>y_i = exp((log(π_i) + g_i)/τ) / Σ_j exp((log(π_j) + g_j)/τ)
</code></pre>
<p>ここで：
- π_i はカテゴリ i の確率
- g_i は標準Gumbel分布からのサンプル
- τ は温度パラメータ</p>
<h4 id="22"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#22">2.2 特徴</a></h4>
<ol>
<li>τ（温度）を小さくしていくと、Gumbel-Softmax分布はカテゴリカル分布に近づきます。</li>
<li>サンプリングした値 y は微分可能です。</li>
</ol>
<p><img alt="Figure 1" src="https://github.com/user-attachments/assets/d325550e-fe33-4129-9fc5-fc867ecd7346" /></p>
<p>図1は、温度τを変化させたときのGumbel-Softmax分布のサンプルを示しています。</p>
<h3 id="3-gumbel-softmax"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#3-gumbel-softmax">3. Gumbel-Softmax推定器</a></h3>
<h4 id="31"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#31">3.1 基本的なアイデア</a></h4>
<p>Gumbel-Softmax推定器の核心は、学習時にカテゴリカル変数のサンプルをGumbel-Softmax分布からのサンプルで置き換えることです。</p>
<h4 id="32-straight-through-st-gumbel-softmax"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#32-straight-through-st-gumbel-softmax">3.2 Straight-Through (ST) Gumbel-Softmax</a></h4>
<p>離散的な値が必要な場合（例：強化学習の行動選択）、以下の手順を踏みます：</p>
<ol>
<li>順伝播時：arg maxを使って離散化</li>
<li>逆伝播時：連続的な近似を使用</li>
</ol>
<p>これにより、離散性を保ちつつ勾配を流すことができます。</p>
<h3 id="4"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#4">4. 実験結果</a></h3>
<p>論文では3つの主要な実験を行っています：</p>
<h4 id="41"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#41">4.1 構造化出力予測</a></h4>
<p>MNISTデータセットの上半分から下半分を予測するタスクです。</p>
<p><img alt="Figure 3" src="https://github.com/user-attachments/assets/5bf9eda7-da7d-42b5-adde-91753722e089" /></p>
<p>結果：Gumbel-Softmax（特にST版）が他の手法を上回る性能を示しました。</p>
<h4 id="42-vae"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#42-vae">4.2 変分オートエンコーダ（VAE）</a></h4>
<p>MNISTデータセットを用いた生成モデルの学習です。</p>
<p><img alt="Figure 4" src="https://github.com/user-attachments/assets/0063a9f7-1578-4e6b-b819-e91d51b4216f" /></p>
<p>結果：ここでもGumbel-Softmaxが最高性能を達成しました。</p>
<h4 id="43"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#43">4.3 半教師あり学習</a></h4>
<p>ラベルありデータが少ない状況での画像分類タスクです。</p>
<p>結果：
- 分類精度：他の手法と同等
- 計算速度：大幅に向上（特にクラス数が多い場合）</p>
<p><img alt="Figure 5" src="https://github.com/user-attachments/assets/f4e46bd4-6482-4c7b-811a-90503a6aae86" /></p>
<h3 id="5"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#5">5. 結論と今後の展望</a></h3>
<h4 id="51"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#51">5.1 主な貢献</a></h4>
<ol>
<li>カテゴリカル分布のための新しい再パラメータ化手法の提案</li>
<li>低分散の勾配推定を実現</li>
<li>様々なタスクでの有効性を実証</li>
</ol>
<h4 id="52"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#52">5.2 今後の展望</a></h4>
<ul>
<li>より複雑なモデルや大規模データセットでの検証</li>
<li>他の応用分野（例：自然言語処理）での活用</li>
<li>温度パラメータの最適な設定方法の研究</li>
</ul>
<p>この研究は、離散変数を扱う機械学習モデルの学習を大きく前進させる可能性を秘めています。特に、大規模なカテゴリカルデータを扱う際の計算効率の向上が期待されます。</p>
<hr />
<p>前提となる知識を追加してより分かりやすく解説</p>
<h3 id="gumbel-softmax_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#gumbel-softmax_1">Gumbel-Softmaxによるカテゴリカル再パラメータ化：機械学習の新しい方法</a></h3>
<h3 id="1_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#1_1">1. はじめに：機械学習とは？</a></h3>
<h4 id="11_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#11_1">1.1 機械学習の基本</a></h4>
<p>機械学習とは、コンピュータにデータから学習させ、タスクを実行する能力を向上させる技術です。例えば：</p>
<ul>
<li>画像認識：写真の中の物体を識別する</li>
<li>音声認識：話し言葉をテキストに変換する</li>
<li>推薦システム：ユーザーの好みに合った商品を提案する</li>
</ul>
<p>これらは全て、大量のデータからパターンを学習することで実現されています。</p>
<h4 id="12_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#12_1">1.2 ニューラルネットワーク</a></h4>
<p>機械学習の中でも特に注目されているのが、脳の仕組みを模倣した「ニューラルネットワーク」です。これは、多数の「ニューロン」（計算単位）を層状に連結したモデルで、複雑なパターンを学習できます。</p>
<h3 id="2"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#2">2. 研究の背景：なぜこの研究が必要だったのか？</a></h3>
<h4 id="21_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#21_1">2.1 離散的なデータの重要性</a></h4>
<p>現実世界のデータには、連続的なもの（身長、体重など）と離散的なもの（性別、血液型など）があります。特に、複数の選択肢から1つを選ぶような「カテゴリカル変数」は非常に一般的です。例えば：</p>
<ul>
<li>言語：単語の選択</li>
<li>画像：ピクセルの色</li>
<li>意思決定：行動の選択</li>
</ul>
<h4 id="22_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#22_1">2.2 従来の手法の問題点</a></h4>
<p>ニューラルネットワークは、通常「バックプロパゲーション」という方法で学習します。これは、出力の誤差を入力側に逆伝播させて、少しずつモデルを調整する方法です。</p>
<p>しかし、カテゴリカル変数のような離散的なデータでは、この方法がうまく機能しません。なぜなら、離散的な選択は「微分不可能」（なめらかに変化しない）だからです。</p>
<h3 id="3-gumbel-softmax_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#3-gumbel-softmax_1">3. Gumbel-Softmax：新しい解決策</a></h3>
<h4 id="31_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#31_1">3.1 基本的なアイデア</a></h4>
<p>研究者たちは、カテゴリカル変数を「連続的に近似する」方法を考案しました。これがGumbel-Softmax分布です。</p>
<p>簡単に言えば：
1. カテゴリカル変数を確率の分布で表現
2. その分布を温度パラメータτで調整可能な連続的な分布に変換
3. 学習中はこの連続的な近似を使用し、実際の使用時は離散的な選択に戻す</p>
<h4 id="32"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#32">3.2 具体的な仕組み</a></h4>
<ol>
<li>各カテゴリに確率を割り当てる（例：赤30%, 青50%, 緑20%）</li>
<li>それぞれにランダムなノイズ（Gumbel分布）を加える</li>
<li>ソフトマックス関数（確率に変換する関数）を適用</li>
<li>温度τで調整（低いτ→よりカテゴリカルに近い、高いτ→よりなめらか）</li>
</ol>
<p><img alt="Figure 1" src="https://github.com/user-attachments/assets/d325550e-fe33-4129-9fc5-fc867ecd7346" /></p>
<p>この図は、温度τを変えたときのGumbel-Softmax分布のサンプルを示しています。τが小さいほど、discrete（離散的）な分布に近づきます。</p>
<h3 id="4_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#4_1">4. 実験：本当に効果があるの？</a></h3>
<p>研究者たちは、この新しい方法が実際に役立つかを確かめるために、いくつかの実験を行いました。</p>
<h4 id="41-mnist"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#41-mnist">4.1 MNISTの画像生成</a></h4>
<p>MNISTは、手書き数字の画像データセットです。この実験では：</p>
<ol>
<li>画像の上半分を入力として与える</li>
<li>ニューラルネットワークに下半分を予測させる</li>
</ol>
<p><img alt="Figure 3" src="https://github.com/user-attachments/assets/5bf9eda7-da7d-42b5-adde-91753722e089" /></p>
<p>結果：Gumbel-Softmaxを使った方法（特にST Gumbel-Softmax）が、他の方法よりも良い結果を出しました。</p>
<h4 id="42-vae_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#42-vae_1">4.2 変分オートエンコーダ（VAE）</a></h4>
<p>VAEは、データの特徴を学習し、新しいデータを生成できるモデルです。MNISTデータセットを使って実験しました。</p>
<p><img alt="Figure 4" src="https://github.com/user-attachments/assets/0063a9f7-1578-4e6b-b819-e91d51b4216f" /></p>
<p>結果：ここでもGumbel-Softmaxが最も良い性能を示しました。</p>
<h4 id="43_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#43_1">4.3 半教師あり学習</a></h4>
<p>これは、一部のデータにしかラベル（正解）がない状況での学習です。例えば、100枚の画像のうち10枚にしか「これは犬」「これは猫」といったラベルがない場合です。</p>
<p>結果：
- 分類の正確さ：他の方法と同じくらい良い
- 計算速度：とても速くなった（特に分類するカテゴリの数が多い場合）</p>
<p><img alt="Figure 5" src="https://github.com/user-attachments/assets/f4e46bd4-6482-4c7b-811a-90503a6aae86" /></p>
<p>この図は、カテゴリ（クラス）の数が増えたときの計算速度の比較です。Gumbel-Softmaxを使うと、特に多くのカテゴリがある場合に大幅に速くなることがわかります。</p>
<h3 id="5_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#5_1">5. まとめと今後の展望</a></h3>
<h4 id="51_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#51_1">5.1 この研究の重要性</a></h4>
<ol>
<li>カテゴリカルな選択を、学習しやすい形に変換する新しい方法を提案</li>
<li>様々な実験で、既存の方法より良い結果を示した</li>
<li>特に、計算速度の大幅な向上を実現</li>
</ol>
<h4 id="52_1"><a class="toclink" href="../../2017/08/05/categorical-reparameterization-with-gumbel-softmax/#52_1">5.2 将来の可能性</a></h4>
<ul>
<li>より複雑な問題への応用（例：自然言語処理、ゲームAIなど）</li>
<li>大規模なデータセットでの検証</li>
<li>他の機械学習技術との組み合わせ</li>
</ul>
<p>この研究は、機械学習がより複雑な現実世界の問題を解決する上で、大きな一歩となる可能性があります。カテゴリカルな選択を含む多くの問題（例：商品の推薦、自動運転の意思決定など）で、より効率的で精度の高いシステムの開発につながるかもしれません。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2016-09-19 00:00:00+00:00">2016年9月19日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/sound/" class="md-meta__link">Sound</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="wavenet-a-generative-model-for-raw-audio"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/">WaveNet: A Generative Model for Raw Audio</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1609.03499">https://arxiv.org/abs/1609.03499</a></li>
<li><a href="https://arxiv.org/pdf/1609.03499">https://arxiv.org/pdf/1609.03499</a></li>
</ul>
<hr />
<h3 id="wavenet"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#wavenet">WaveNet: 生の音声データに対する生成モデル</a></h3>
<h3 id="1"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#1">1. はじめに</a></h3>
<p>WaveNetは、生の音声波形を直接モデル化する深層生成モデルです。このモデルは、以下の特徴を持っています:</p>
<ul>
<li>完全に確率的で自己回帰的</li>
<li>各音声サンプルの予測分布は、それ以前のすべてのサンプルに条件付けられる</li>
<li>1秒あたり数万サンプルの音声データを効率的に学習可能</li>
</ul>
<p>WaveNetは以下の分野で優れた性能を示しました:</p>
<ul>
<li>テキスト音声合成(TTS)において、人間のリスナーが最も自然だと評価</li>
<li>英語と中国語の両方で、パラメトリック方式と連結方式の最高システムを上回る</li>
<li>1つのWaveNetで多数の話者の特徴を同等の忠実度で捉えられる</li>
<li>話者IDを条件として与えることで、異なる話者の音声を生成可能</li>
<li>音楽のモデル化において、新規性が高く現実的な音楽フラグメントを生成</li>
<li>音素認識などの識別モデルとしても有望な結果</li>
</ul>
<h3 id="2-wavenet"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#2-wavenet">2. WaveNetの構造</a></h3>
<h4 id="21"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#21">2.1 希釈因果畳み込み</a></h4>
<p>WaveNetの主要な構成要素は因果畳み込みです。これにより、モデルがデータのモデル化順序に違反しないようにしています。</p>
<p><img alt="Dilated Causal Convolutions" src="https://github.com/user-attachments/assets/a9ee7e80-aafa-439c-a88e-5cc262dd3cd2" /></p>
<p>希釈畳み込みを使用することで、受容野を大幅に拡大しつつ、計算コストを抑えています。</p>
<h4 id="22"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#22">2.2 ソフトマックス分布</a></h4>
<p>WaveNetは、各時点の音声サンプルの条件付き分布をソフトマックス分布でモデル化します。これにより、任意の分布を柔軟にモデル化できます。</p>
<p>生の音声データは通常16ビット整数値で保存されるため、65,536の出力を持つソフトマックス層が必要になります。これを扱いやすくするために、μ法圧縮変換を適用し、256の値に量子化しています。</p>
<h4 id="23"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#23">2.3 ゲート付き活性化ユニット</a></h4>
<p>WaveNetは、以下のようなゲート付き活性化ユニットを使用します:</p>
<pre><code>z = tanh(Wf,k * x) ⊙ σ(Wg,k * x)
</code></pre>
<p>ここで、⊙は要素ごとの乗算、σ(·)はシグモイド関数、kは層のインデックス、fとgはそれぞれフィルターとゲートを表し、Wは学習可能な畳み込みフィルターです。</p>
<h4 id="24"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#24">2.4 残差接続とスキップ接続</a></h4>
<p>モデルの収束を速め、より深いネットワークの学習を可能にするために、残差接続とパラメータ化されたスキップ接続を使用しています。</p>
<p><img alt="Residual and Skip Connections" src="https://github.com/user-attachments/assets/061f6420-f13c-4dec-82d9-2ca637e5998b" /></p>
<h4 id="25-wavenet"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#25-wavenet">2.5 条件付きWaveNet</a></h4>
<p>追加の入力hを与えることで、WaveNetは条件付き分布p(x|h)をモデル化できます。条件付けには、グローバル条件付けとローカル条件付けの2種類があります。</p>
<h3 id="3"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#3">3. 実験</a></h3>
<h4 id="31"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#31">3.1 複数話者の音声生成</a></h4>
<p>VCTKコーパスを使用し、109人の話者の44時間のデータセットで学習を行いました。テキストに条件付けせずに自由形式の音声を生成しました。</p>
<p>結果:
- 存在しないが人間の言語に似た単語を滑らかに生成
- 1つのWaveNetで109人全ての話者の特徴を捉えることができた
- 話者を増やすことで検証セットのパフォーマンスが向上
- 音声以外の特徴（音響、録音品質、呼吸、口の動きなど）も模倣</p>
<h4 id="32-tts"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#32-tts">3.2 テキスト音声合成(TTS)</a></h4>
<p>北米英語と中国語標準語のそれぞれ24.6時間と34.8時間のデータセットを使用しました。</p>
<p>結果:
- WaveNetは、ベースラインのパラメトリック方式と連結方式の音声合成システムを上回りました
- 5段階の自然性MOSで4.0以上を達成（過去最高スコア）
- 最高の合成音声と自然音声とのMOSの差を、英語で51%、中国語で69%縮小</p>
<p><img alt="TTS Preference Scores" src="https://github.com/user-attachments/assets/db6c6211-deef-4fc8-a844-7bf5b348d4d2" /></p>
<h4 id="33"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#33">3.3 音楽</a></h4>
<p>MagnaTagATuneデータセット（約200時間）とYouTubeピアノデータセット（約60時間）を使用しました。</p>
<p>結果:
- 受容野を拡大することが音楽的なサンプルを生成するために重要
- サンプルは調和的で美的に魅力的
- タグ（ジャンル、楽器など）に基づく条件付き生成が可能</p>
<h4 id="34"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#34">3.4 音声認識</a></h4>
<p>TIMITデータセットを使用して音声認識タスクを行いました。</p>
<p>結果:
- 生の音声から直接学習したモデルとしては最高の18.8 PER（音素誤り率）を達成</p>
<h3 id="4"><a class="toclink" href="../../2016/09/19/wavenet-a-generative-model-for-raw-audio/#4">4. 結論</a></h3>
<p>WaveNetは、音声波形レベルで直接動作する深層生成モデルです。自己回帰的で因果的なフィルターと希釈畳み込みを組み合わせることで、音声信号の長期的な時間依存性をモデル化することができます。</p>
<p>TTSタスクでは、主観的な自然さにおいて現在最高のTTSシステムを上回る性能を示しました。また、音楽音声のモデリングや音声認識においても非常に有望な結果を示しました。</p>
<p>これらの結果は、WaveNetが音声生成に依存する多くのアプリケーションに対して汎用的で柔軟なフレームワークを提供する可能性を示唆しています。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2015-11-18 00:00:00+00:00">2015年11月18日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="deep-unsupervised-learning-using-nonequilibrium-thermodynamics"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1503.03585">https://arxiv.org/abs/1503.03585</a></li>
<li><a href="https://arxiv.org/pdf/1503.03585">https://arxiv.org/pdf/1503.03585</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#_1">非平衡熱力学を用いた深層教師なし学習</a></h3>
<h3 id="1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#1">1. はじめに</a></h3>
<p>この論文は、複雑なデータセットをモデル化するための新しい確率モデルの枠組みを提案しています。この手法は非平衡統計物理学の概念に触発されており、データ分布の構造を徐々に破壊する前方拡散過程と、その構造を復元する逆拡散過程を学習することで、柔軟かつ扱いやすい生成モデルを実現しています。</p>
<h3 id="2"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#2">2. 主要な概念</a></h3>
<h4 id="21"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#21">2.1 拡散確率モデル</a></h4>
<p>提案されたモデルは以下の特徴を持ちます：</p>
<ol>
<li>モデル構造の高い柔軟性</li>
<li>正確なサンプリング</li>
<li>他の分布との容易な乗算（例：事後分布の計算）</li>
<li>モデルの対数尤度と個々の状態の確率の効率的な評価</li>
</ol>
<h4 id="22"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#22">2.2 前方拡散過程</a></h4>
<p>データ分布q(x^(0))から始まり、単純な分布π(y)（例：ガウス分布）に向かって徐々に拡散していく過程を定義します。</p>
<p>q(x^(0···T)) = q(x^(0)) ∏^T_t=1 q(x^(t)|x^(t-1))</p>
<h4 id="23"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#23">2.3 逆拡散過程</a></h4>
<p>生成モデルは、前方過程の逆を学習します：</p>
<p>p(x^(0···T)) = p(x^(T)) ∏^T_t=1 p(x^(t-1)|x^(t))</p>
<p>ここで、p(x^(T)) = π(x^(T))です。</p>
<h3 id="3"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#3">3. モデルの学習</a></h3>
<h4 id="31"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#31">3.1 目的関数</a></h4>
<p>モデルの対数尤度の下界を最大化することで学習を行います：</p>
<p>L ≥ K = -∑^T_t=2 E_q(x^(0),x^(t))[D_KL(q(x^(t-1)|x^(t),x^(0))||p(x^(t-1)|x^(t)))] + H_q(X^(T)|X^(0)) - H_q(X^(1)|X^(0)) - H_p(X^(T))</p>
<h4 id="32"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#32">3.2 拡散率の設定</a></h4>
<p>ガウス拡散の場合、拡散率β_tは勾配上昇法によって学習されます。二項拡散の場合は、各ステップで一定の割合の信号を消去するように設定されます。</p>
<h3 id="4"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#4">4. 実験結果</a></h3>
<p>著者らは以下のデータセットでモデルを評価しました：</p>
<ol>
<li>2次元スイスロール分布</li>
<li>バイナリハートビート分布</li>
<li>MNIST手書き数字</li>
<li>CIFAR-10自然画像</li>
<li>樹皮テクスチャ画像</li>
<li>デッドリーブス画像</li>
</ol>
<p><img alt="Figure 1: スイスロール分布の学習結果" src="https://github.com/user-attachments/assets/ed8af005-d6ad-495d-a4c4-23db93158cbe" /></p>
<p>この図は、2次元スイスロール分布に対する学習結果を示しています。上段は前方拡散過程、中段は学習された逆拡散過程、下段は逆拡散過程のドリフト項を表しています。</p>
<h3 id="5"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#5">5. 主な結果</a></h3>
<ol>
<li>提案手法は、様々なデータ分布に対して高品質なサンプルを生成できることが示されました。</li>
<li>学習されたモデルを用いて、画像の修復やノイズ除去などのタスクが可能であることが実証されました。</li>
<li>一部のデータセットにおいて、既存手法を上回る対数尤度を達成しました。</li>
</ol>
<h3 id="6"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#6">6. 結論</a></h3>
<p>非平衡熱力学の概念を応用した新しい確率モデリング手法を提案しました。この手法は、高い柔軟性と扱いやすさを兼ね備えており、様々なデータセットに対して効果的であることが示されました。今後、この手法が深層教師なし学習の分野に新たな可能性をもたらすことが期待されます。</p>
<hr />
<h2 id="deep-unsupervised-learning-using-nonequilibrium-thermodynamics_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#deep-unsupervised-learning-using-nonequilibrium-thermodynamics_1">高校生のための Deep Unsupervised Learning using Nonequilibrium Thermodynamics 解説</a></h2>
<h3 id="1_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#1_1">1. はじめに</a></h3>
<p>この論文は、コンピューターがデータの特徴を学習し、新しいデータを生成する方法について新しいアイデアを提案しています。この方法は、物理学の「非平衡熱力学」という考え方からヒントを得ています。</p>
<h3 id="2_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#2_1">2. 主なアイデア</a></h3>
<h4 id="21_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#21_1">2.1 拡散モデル</a></h4>
<p>この新しい方法を「拡散モデル」と呼びます。特徴は以下の通りです：</p>
<ol>
<li>いろいろな種類のデータに対応できる</li>
<li>正確にデータを生成できる</li>
<li>他の情報と簡単に組み合わせられる</li>
<li>データの確率を計算しやすい</li>
</ol>
<h4 id="22_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#22_1">2.2 データを「溶かす」過程</a></h4>
<p>まず、元のデータを少しずつ「溶かして」いき、最終的には完全にランダムな状態（例えば、テレビの砂嵐のような状態）にします。</p>
<h4 id="23_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#23_1">2.3 データを「戻す」過程</a></h4>
<p>次に、ランダムな状態から少しずつ元のデータらしい状態に「戻す」方法を学習します。これが、新しいデータを生成する方法になります。</p>
<h3 id="3_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#3_1">3. コンピューターの学習方法</a></h3>
<p>コンピューターは、「戻す」過程をうまく行えるように訓練されます。具体的には、元のデータと生成されたデータの違いが小さくなるように学習します。</p>
<h3 id="4_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#4_1">4. 実験結果</a></h3>
<p>研究者たちは、この方法を以下のようなデータで試しました：</p>
<ol>
<li>渦巻き型の2次元データ</li>
<li>規則的に繰り返すバイナリデータ</li>
<li>手書き数字（MNIST）</li>
<li>自然画像（CIFAR-10）</li>
<li>木の樹皮の画像</li>
<li>重なり合う円の画像</li>
</ol>
<p>この図は、渦巻き型のデータ（スイスロール分布）に対する学習結果を示しています。上段は「溶かす」過程、中段は学習された「戻す」過程を表しています。</p>
<h3 id="5_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#5_1">5. 主な成果</a></h3>
<ol>
<li>この方法は、様々な種類のデータに対して、本物そっくりのデータを生成できました。</li>
<li>画像の一部が欠けていても、それを補完することができました。</li>
<li>一部のデータセットでは、他の方法よりも優れた性能を示しました。</li>
</ol>
<h3 id="6_1"><a class="toclink" href="../../2015/11/18/deep-unsupervised-learning-using-nonequilibrium-thermodynamics/#6_1">6. まとめ</a></h3>
<p>この研究は、物理学のアイデアを使って新しい機械学習の方法を作り出しました。この方法は、様々なデータに対して柔軟に対応でき、扱いやすいという特徴があります。将来、この方法が機械学習の世界に新しい可能性をもたらすことが期待されています。</p>
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  <a class="md-pagination__link" href="../../">1</a> <span class="md-pagination__dots">..</span> <a class="md-pagination__link" href="../3/">3</a> <a class="md-pagination__link" href="../4/">4</a> <span class="md-pagination__current">5</span> <a class="md-pagination__link" href="../6/">6</a>
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2014 - 2025 Sojiro's Blog. All rights reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://x.com/sojiro14" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/sojiro14" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>