
<!doctype html>
<html lang="ja" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://blog.sojiro.me/summaries/page/3/">
      
      
        <link rel="prev" href="../../../blog/archive/2014/">
      
      
        <link rel="next" href="../../category/artificial-intelligence/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Recent Posts - Sojiro's Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-ECN7E21ZM0"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-ECN7E21ZM0",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-ECN7E21ZM0",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Recent Posts - Sojiro's Blog" >
      
        <meta  property="og:description"  content="None" >
      
        <meta  property="og:image"  content="https://blog.sojiro.me/assets/images/social/summaries/page/3/index.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://blog.sojiro.me/summaries/page/3/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Recent Posts - Sojiro's Blog" >
      
        <meta  name="twitter:description"  content="None" >
      
        <meta  name="twitter:image"  content="https://blog.sojiro.me/assets/images/social/summaries/page/3/index.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#recent-posts" class="md-skip">
          コンテンツにスキップ
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="ヘッダー">
    <a href="../../.." title="Sojiro&#39;s Blog" class="md-header__button md-logo" aria-label="Sojiro's Blog" data-md-component="logo">
      
  <img src="../../../assets/images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sojiro's Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Recent Posts
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="検索" placeholder="検索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="検索">
        
        <button type="reset" class="md-search__icon md-icon" title="クリア" aria-label="クリア" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            検索を初期化
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="ナビゲーション" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Sojiro&#39;s Blog" class="md-nav__button md-logo" aria-label="Sojiro's Blog" data-md-component="logo">
      
  <img src="../../../assets/images/logo.png" alt="logo">

    </a>
    Sojiro's Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Recent Posts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2024/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2022/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2022
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2017/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2017
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2016/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2016
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2015/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2015
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2014/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2014
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/aws/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AWS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/anaconda/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anaconda
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/android-studio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Android Studio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/bigquery/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BigQuery
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/bower/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bower
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/cpan/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CPAN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/canvas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Canvas
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/chef/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chef
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/datastore/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Datastore
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/disqus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Disqus
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/domain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Domain
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/erc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ERC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/ethereum/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ethereum
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gae/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GAE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gce/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCE
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gcp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/gcs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/git/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Git
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/github/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GitHub
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/github-pages/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Github Pages
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/grunt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Grunt
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/html5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HTML5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/heroku/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Heroku
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/homebrew/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Homebrew
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/hubot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hubot
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/irc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    IRC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/json-schema/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    JSON Schema
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/java/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Java
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/liveportrait/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LivePortrait
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/mean/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MEAN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/mongodb/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MongoDB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/mysql/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MySQL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/nft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    NFT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/nodejs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Node.js
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/oop/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    OOP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/octopress/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Octopress
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/perl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Perl
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/repl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    REPL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/rvm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RVM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/redis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Redis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/reply/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reply
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/ruby/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ruby
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/ruby-on-rails/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ruby on Rails
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/shell/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shell
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/slack/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slack
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/task-queue/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Task Queue
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/vagrant/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vagrant
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/vim/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vim
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/vuepress/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VuePress
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/web/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Web
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/webrtc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    WebRTC
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/wordpress/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    WordPress
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/yeoman/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Yeoman
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/npm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    npm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/revealjs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    reveal.js
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/screen/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    screen
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/yo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    yo
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Paper Summaries
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Paper Summaries
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
      
    
  
  
    <li class="md-nav__item">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="../../" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Recent Posts
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2024/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2023/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2023
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2022/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2022
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2021/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2021
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2020/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2020
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2019/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2019
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2018/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2018
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2017/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2017
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2016/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2016
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2015/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2015
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2014/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2014
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/1972/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1972
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/artificial-intelligence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Artificial Intelligence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/audio-and-speech-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Audio and Speech Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/call-center/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Call Center
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/computation-and-language/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computation and Language
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/computer-science/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computer Science
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/computer-vision-and-pattern-recognition/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computer Vision and Pattern Recognition
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/digital-libraries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Digital Libraries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/electrical-engineering-and-systems-science/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Electrical Engineering and Systems Science
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/emergence/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/information-retrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Information Retrieval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/machine-learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Machine Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/reductionism/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reductionism
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/sound/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sound
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/speech-to-text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speech to text
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/statistics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Statistics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/synthetic-biology/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Synthetic Biology
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%82%B5%E3%83%83%E3%82%AB%E3%83%BC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    サッカー
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%BC%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%87%E3%83%BC%E3%82%BF/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    シミューレーションデータ
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%84/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    スポーツ
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E3%83%9E%E3%83%AB%E3%83%81%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    マルチエージェント
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E5%9F%BA%E7%9B%A4%E3%83%A2%E3%83%87%E3%83%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    基盤モデル
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E5%BB%BA%E7%AF%89%E7%9A%84%E6%BD%9C%E5%9C%A8%E4%BE%A1%E5%80%A4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    建築的潜在価値
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    強化学習
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    機械学習
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    深層学習
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E7%A4%BE%E4%BC%9A%E7%9A%84%E4%BE%A1%E5%80%A4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    社会的価値
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    言語モデル
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../category/%E9%AB%98%E7%B5%8C%E5%B9%B4%E8%B3%83%E8%B2%B8%E3%83%9E%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%B3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    高経年賃貸マンション
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目次">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="recent-posts">Recent Posts</h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-10-12 00:00:00+00:00">2023年10月12日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/artificial-intelligence/" class="md-meta__link">Artificial Intelligence</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="learn-from-model-beyond-fine-tuning-a-survey"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/">Learn From Model Beyond Fine-Tuning: A Survey</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2310.08184">https://arxiv.org/abs/2310.08184</a></li>
<li><a href="https://arxiv.org/pdf/2310.08184">https://arxiv.org/pdf/2310.08184</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_1">序論</a></h3>
<p>本論文は、従来のファインチューニングを超えた「Learn From Model（LFM）」アプローチについて包括的にレビューします。LFMは、既存の大規模言語モデル（FM）を活用し、新しいタスクへの適応や性能向上を図る手法です。</p>
<h3 id="_2"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_2">モデルチューニング</a></h3>
<h4 id="_3"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_3">ファインチューニング</a></h4>
<p>ファインチューニングは、既存のモデルに新しいデータで再訓練を行い、特定のタスクに適応させる方法です。これにより、モデルのパフォーマンスを向上させることができますが、計算コストが高く、過学習のリスクもあります。</p>
<h4 id="_4"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_4">アダプターチューニング</a></h4>
<p>アダプターチューニングは、モデルの内部パラメータを固定し、追加のトレーニング可能なパラメータ（アダプター）を挿入して、特定のタスクに適応させる方法です。これにより、計算コストを削減しつつ、性能を維持します。</p>
<h4 id="_5"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_5">プロンプトチューニング</a></h4>
<p>プロンプトチューニングは、モデルのパラメータを固定し、最適なプロンプトを設計してモデルの性能を引き出す方法です。ホワイトボックスとブラックボックスの設定があり、後者はモデルのパラメータにアクセスできない状況でも効果を発揮します。</p>
<h4 id="_6"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_6">インストラクションチューニング</a></h4>
<p>インストラクションチューニングは、モデルに命令形式でデータを提供し、特定のタスクを実行する能力を向上させる方法です。これにより、見たことのないタスクにも対応できる汎用性が向上します。</p>
<h3 id="_7"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_7">モデル蒸留</a></h3>
<p>モデル蒸留は、大規模な教師モデルから小規模な生徒モデルへ知識を移転し、計算リソースが限られた環境でも高性能を維持する手法です。</p>
<h3 id="_8"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_8">モデル再利用</a></h3>
<p>モデル再利用は、複数のモデルの予測を組み合わせて全体の性能を向上させる方法です。これにより、個々のモデルの強みを活かしつつ、弱点を補完します。</p>
<h3 id="_9"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_9">メタラーニング</a></h3>
<p>メタラーニングは、新しいタスクに迅速に適応できるモデルを設計する手法です。これにより、連続的な学習や複数タスクの同時処理が可能になります。</p>
<h3 id="_10"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_10">モデル編集</a></h3>
<p>モデル編集は、モデルの知識を直接調整して性能を向上させる方法です。これにより、再訓練のコストを抑えつつ、モデルの適応性を高めます。</p>
<h3 id="_11"><a class="toclink" href="../../2023/10/12/learn-from-model-beyond-fine-tuning/#_11">結論</a></h3>
<p>LFMは、データ中心の学習を超え、既存の大規模モデルを活用する新しいパラダイムです。これにより、計算コストの削減、データプライバシーの保護、モデルの汎用性の向上が期待されます。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-10-02 00:00:00+00:00">2023年10月2日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="textbooks-are-all-you-need"><a class="toclink" href="../../2023/10/02/textbooks-are-all-you-need/">Textbooks Are All You Need</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2306.11644">https://arxiv.org/abs/2306.11644</a></li>
<li><a href="https://arxiv.org/pdf/2306.11644">https://arxiv.org/pdf/2306.11644</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2023/10/02/textbooks-are-all-you-need/#_1">序論</a></h3>
<p>本論文では、コード生成に特化した新しい大規模言語モデルphi-1を紹介します。このモデルは、他の競合モデルに比べて大幅に小型化されているにもかかわらず、高い性能を発揮します。</p>
<h3 id="_2"><a class="toclink" href="../../2023/10/02/textbooks-are-all-you-need/#_2">研究の目的</a></h3>
<p>モデルの性能向上には高品質なデータが重要であることを示し、特に「教科書品質」のデータを使用することで、小規模なモデルでも高性能を達成できることを目指しています。</p>
<h3 id="_3"><a class="toclink" href="../../2023/10/02/textbooks-are-all-you-need/#_3">方法</a></h3>
<p>phi-1は、GPT-3.5を使用して生成された教科書データと、Webから収集された高品質なデータを組み合わせて訓練されました。また、Pythonのコード生成タスクに特化したデータセットで微調整を行いました。</p>
<h3 id="_4"><a class="toclink" href="../../2023/10/02/textbooks-are-all-you-need/#_4">結果</a></h3>
<p>phi-1は、HumanEvalとMBPPのベンチマークで高い精度を達成しました。特に、微調整後のphi-1は、多くの既存モデルを上回る性能を示しています。</p>
<h3 id="_5"><a class="toclink" href="../../2023/10/02/textbooks-are-all-you-need/#_5">結論</a></h3>
<p>高品質なデータを使用することで、計算資源を大幅に節約しつつ、高性能なモデルを訓練できることが示されました。phi-1は、小規模なデータセットと少ない訓練時間で優れた結果を達成しています。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-08-03 00:00:00+00:00">2023年8月3日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/sound/" class="md-meta__link">Sound</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/">MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2308.01546">https://arxiv.org/abs/2308.01546</a></li>
<li><a href="https://arxiv.org/pdf/2308.01546">https://arxiv.org/pdf/2308.01546</a></li>
</ul>
<hr />
<h3 id="musicldm"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#musicldm">MusicLDM: テキストから音楽生成を改善する研究</a></h3>
<h3 id="1"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#1">1. 研究の概要と背景</a></h3>
<p>この研究は、テキストから音楽を生成する新しいAIモデル「MusicLDM」を提案しています。</p>
<h4 id="11"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#11">1.1 主な課題</a></h4>
<p>テキストから音楽を生成する際の2つの主要な課題があります：</p>
<ol>
<li>学習データの不足</li>
<li>画像生成と比べて、テキストと音楽のペアデータが少ない</li>
<li>
<p>音楽には旋律、ハーモニー、リズム、音色など複雑な要素がある</p>
</li>
<li>
<p>著作権とコピー問題</p>
</li>
<li>生成された音楽が既存の曲に似すぎると著作権侵害の恐れ</li>
<li>オリジナリティのある音楽生成が必要</li>
</ol>
<h4 id="12"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#12">1.2 提案手法</a></h4>
<p>研究チームは以下の2つのアプローチで解決を図りました：</p>
<ol>
<li>MusicLDMモデルの開発</li>
<li>Stable DiffusionとAudioLDMのアーキテクチャを音楽生成用に最適化</li>
<li>
<p>CLAPとHifi-GANを音楽データで再学習</p>
</li>
<li>
<p>新しいデータ拡張手法の提案</p>
</li>
<li>ビート同期オーディオミックスアップ(BAM)</li>
<li>ビート同期潜在空間ミックスアップ(BLM)</li>
</ol>
<h3 id="2-musicldm"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#2-musicldm">2. MusicLDMの技術詳細</a></h3>
<h4 id="21"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#21">2.1 モデルのアーキテクチャ</a></h4>
<pre><code class="language-mermaid">graph LR
    %% Input Section
    AW[Audio Waveform] --&gt; |STFT+MelFB| MS[Mel-spectrogram]
    IT[Input Text: 'A spectacular dramatic trailer']

    %% CLAP Processing
    AW --&gt; |Audio Encoder| CAE[CLAP Audio Encoder]
    IT --&gt; |Text Encoder| CTE[CLAP Text Encoder]

    %% VAE Processing
    MS --&gt; VAE_E[VAE Encoder]
    VAE_E --&gt; LR[Latent Representation]

    %% U-Net Diffusion
    subgraph LDM[U-Net Latent Diffusion Model]
        direction LR
        F1[FiLM] --&gt; UN1[U-Net Block 1]
        UN1 --&gt; UN2[U-Net Block 2]
        UN2 --&gt; UN3[...]
        CAE --&gt; |Audio Embedding| F1
        CTE --&gt; |Text Embedding| F1
    end

    LR --&gt; LDM

    %% Output Processing
    LDM --&gt; VAE_D[VAE Decoder]
    VAE_D --&gt; |OR| HG[Hifi-GAN]

    %% Styling
    classDef input fill:#e6f3ff,stroke:#2196F3
    classDef encoder fill:#ffece6,stroke:#FF5722
    classDef vae fill:#e6ffe6,stroke:#4CAF50
    classDef diffusion fill:#ffe6f9,stroke:#9C27B0

    class AW,IT,MS input
    class CAE,CTE encoder
    class VAE_E,VAE_D,LR vae
    class LDM,F1,UN1,UN2,UN3 diffusion

    %% Notes
    subgraph Legend
        I[Input] ---|STFT| E[Encoding] ---|Diffusion| D[Decoding]
    end

</code></pre>
<p>MusicLDMは以下の3つの主要コンポーネントで構成されています：</p>
<ol>
<li>CLAP (Contrastive Language-Audio Pretraining)</li>
<li>テキストと音声の関係性を学習するモデル</li>
<li>
<p>音声エンコーダーとテキストエンコーダーを含む</p>
</li>
<li>
<p>VAE (Variational Auto-Encoder)</p>
</li>
<li>音声をより扱いやすい潜在表現に変換</li>
<li>
<p>エンコーダーとデコーダーで構成</p>
</li>
<li>
<p>潜在拡散モデル</p>
</li>
<li>U-Net構造を持つ</li>
<li>テキストの特徴を条件として音楽を生成</li>
</ol>
<h4 id="22"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#22">2.2 ビート同期ミックスアップ戦略</a></h4>
<pre><code class="language-mermaid">graph LR
    subgraph Pre-Processing
        MD[Music Dataset] --&gt; BT[Beat Transformer]
        BT --&gt; |tempo| TG[Tempo Grouping]
        BT --&gt; |downbeat| DA[Downbeat Alignment]
    end

    subgraph BAM[Beat-Synchronous Audio Mix-Up]
        TG --&gt; |aligned pairs| AM[Audio Mixing]
        DA --&gt; |aligned pairs| AM
        AM --&gt; CLAP
        CLAP --&gt; DM1[Diffusion Model]
    end

    subgraph BLM[Beat-Synchronous Latent Mix-Up]
        TG --&gt; |aligned pairs| VAE[VAE Encoder]
        DA --&gt; |aligned pairs| VAE
        VAE --&gt; LM[Latent Mixing]
        LM --&gt; DM2[Diffusion Model]
    end

    style Pre-Processing fill:#e6f3ff
    style BAM fill:#e6ffe6
    style BLM fill:#ffe6f9

    %% Adding notes
    classDef note fill:#fff4e6,stroke:#ffa94d
    class MD,BT,TG,DA note
</code></pre>
<p>2つのミックスアップ戦略が提案されています：</p>
<ol>
<li>ビート同期オーディオミックスアップ(BAM)</li>
<li>音声波形レベルでのミックス</li>
<li>テンポとビートを合わせて混合</li>
<li>
<p>音楽的な一貫性を保持</p>
</li>
<li>
<p>ビート同期潜在空間ミックスアップ(BLM)</p>
</li>
<li>VAEの潜在空間でのミックス</li>
<li>より自然な音楽生成が可能</li>
<li>計算コストは高い</li>
</ol>
<h3 id="3"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#3">3. 実験と結果</a></h3>
<h4 id="31"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#31">3.1 実験設定</a></h4>
<ul>
<li>データセット：Audiostock（9,000曲の訓練データ、1,000曲のテストデータ）</li>
<li>サンプリングレート：16kHz</li>
<li>音声長：10.24秒</li>
</ul>
<h4 id="32"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#32">3.2 評価指標</a></h4>
<ol>
<li>生成品質</li>
<li>FD (Frechet Distance)</li>
<li>IS (Inception Score)</li>
<li>
<p>KL (Kullback-Leibler) ダイバージェンス</p>
</li>
<li>
<p>テキストとの関連性</p>
</li>
<li>
<p>テキスト-音声類似度</p>
</li>
<li>
<p>独創性</p>
</li>
<li>最近傍音声類似度比率</li>
</ol>
<h4 id="33"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#33">3.3 主な実験結果</a></h4>
<ol>
<li>生成品質の比較：</li>
<li>MusicLDMは既存モデルより優れた性能</li>
<li>
<p>BLMが最も高い品質を達成</p>
</li>
<li>
<p>テキストとの関連性：</p>
</li>
<li>オリジナルMusicLDMが最高スコア</li>
<li>
<p>ミックスアップ戦略でもある程度の関連性を維持</p>
</li>
<li>
<p>独創性評価：</p>
</li>
<li>BLMが最も低い類似度比率を達成</li>
<li>コピー問題の軽減に効果的</li>
</ol>
<h3 id="4"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#4">4. 制限事項と今後の課題</a></h3>
<ol>
<li>サンプリングレートの制限</li>
<li>現在は16kHzで生成</li>
<li>
<p>音楽制作標準の44.1kHzへの対応が必要</p>
</li>
<li>
<p>リソース制約</p>
</li>
<li>より大規模なデータセットでの検証が必要</li>
<li>
<p>GPU処理能力の制限</p>
</li>
<li>
<p>音楽同期技術</p>
</li>
<li>ビート以外の同期方法の探索</li>
<li>調性やインストゥルメントの整合性</li>
</ol>
<h3 id="5"><a class="toclink" href="../../2023/08/03/musicldm-enhancing-novelty-in-text-to-music-generation-using-beat-synchronous-mixup-strategies/#5">5. 結論と展望</a></h3>
<p>MusicLDMは以下の点で革新的な成果を示しました：</p>
<ol>
<li>技術的成果</li>
<li>高品質な音楽生成を実現</li>
<li>データ効率の改善</li>
<li>
<p>コピー問題の軽減</p>
</li>
<li>
<p>実用的意義</p>
</li>
<li>音楽制作支援への応用</li>
<li>
<p>創造的表現の新しい可能性</p>
</li>
<li>
<p>今後の発展</p>
</li>
<li>より高品質な音楽生成</li>
<li>実用的なアプリケーション開発</li>
</ol>
<p>研究チームは、特にBLM戦略の効果を強調し、テキストから音楽を生成する技術の新しい可能性を示しました。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-08-02 00:00:00+00:00">2023年8月2日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約2分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="attention-is-all-you-need"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/">Attention Is All You Need</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></li>
<li><a href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_1">序論</a></h3>
<p>この論文では、従来のリカレントニューラルネットワーク（RNN）や畳み込みニューラルネットワーク（CNN）を排除し、セルフアテンション機構（Self-Attention）のみを使用した新しいネットワークアーキテクチャ「Transformer」を提案します。</p>
<h3 id="_2"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_2">背景</a></h3>
<p>リカレントモデルはシーケンスの各位置を順次処理するため、並列化が困難でした。一方、アテンション機構はシーケンス内の全ての位置間の依存関係を捉えることができ、計算効率の向上が期待されます。</p>
<h3 id="_3"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_3">モデルアーキテクチャ</a></h3>
<h4 id="_4"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_4">エンコーダとデコーダ</a></h4>
<ul>
<li><strong>エンコーダ</strong>: セルフアテンション機構とポイントワイズの全結合層を持つ。</li>
<li><strong>デコーダ</strong>: エンコーダと同様の構造に加え、エンコーダの出力に対するアテンション機構を持つ。</li>
</ul>
<h4 id="_5"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_5">アテンションメカニズム</a></h4>
<ul>
<li><strong>スケールド・ドットプロダクトアテンション</strong>: クエリとキーのドット積にスケーリングを施し、ソフトマックス関数で重みを計算。</li>
<li><strong>マルチヘッドアテンション</strong>: 複数のアテンション機構を並行して実行し、異なる表現空間から情報を抽出。</li>
</ul>
<h3 id="_6"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_6">訓練方法</a></h3>
<ul>
<li><strong>データ</strong>: WMT 2014英独・英仏翻訳データセットを使用。</li>
<li><strong>ハードウェア</strong>: 8つのNVIDIA P100 GPUで訓練。</li>
<li><strong>最適化手法</strong>: Adamオプティマイザを使用し、学習率を段階的に変化。</li>
</ul>
<h3 id="_7"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_7">結果</a></h3>
<ul>
<li><strong>性能向上</strong>: Transformerモデルは、従来の最先端モデルよりも高いBLEUスコアを達成。</li>
<li><strong>効率性</strong>: 同等の性能を持つ他のモデルに比べて、訓練にかかる時間が大幅に短縮。</li>
</ul>
<h3 id="_8"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_8">結論</a></h3>
<p>Transformerは、リカレントや畳み込み層を使わずに高い性能と効率を実現する新しいアーキテクチャです。この研究は、アテンション機構の可能性を示し、今後のモデル設計に大きな影響を与えるでしょう。</p>
<hr />
<h3 id="1"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#1">1. 概要と重要性</a></h3>
<p>主なポイント:
- RNNやCNNを使用せず、attention機構のみで構成された初めての系列変換モデル
- 並列処理が容易で学習が高速
- 機械翻訳タスクで当時の最高性能を達成
- 現代の大規模言語モデルの基礎となったアーキテクチャ</p>
<h3 id="2-transformer"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#2-transformer">2. Transformerの基本構造</a></h3>
<h4 id="21"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#21">2.1 全体アーキテクチャ</a></h4>
<p><img alt="Transformer Architecture" src="https://github.com/user-attachments/assets/0b43806c-8786-4cab-9fd2-caaff444c2c6" /></p>
<p>Transformerは以下の主要コンポーネントで構成されています:</p>
<ul>
<li>エンコーダー: 入力系列を処理</li>
<li>デコーダー: 出力系列を生成</li>
<li>Multi-Head Attention: 複数の注意機構を並列に実行</li>
<li>Position-wise Feed-Forward Networks: 位置ごとの全結合層</li>
</ul>
<h4 id="22"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#22">2.2 主要な特徴</a></h4>
<ol>
<li>Self-Attention</li>
<li>系列内の異なる位置間の関係性を計算</li>
<li>長距離依存関係の学習が容易</li>
<li>
<p>並列計算が可能</p>
</li>
<li>
<p>Multi-Head Attention</p>
</li>
<li>異なる表現部分空間からの情報を同時に注目</li>
<li>
<p>複数のattentionを並列に計算</p>
</li>
<li>
<p>Position Encoding</p>
</li>
<li>系列の順序情報を保持するため</li>
<li>正弦波関数を使用した位置エンコーディング</li>
</ol>
<h3 id="3-attention"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#3-attention">3. Attention機構の詳細</a></h3>
<h4 id="31-scaled-dot-product-attention"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#31-scaled-dot-product-attention">3.1 Scaled Dot-Product Attention</a></h4>
<p><img alt="Attention Mechanism" src="https://github.com/user-attachments/assets/16f74df8-13d2-4cc0-be5c-8875d2c8dc75" /></p>
<p>数式: $$Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V$$</p>
<p>特徴:
- Query, Key, Valueの3つの要素で構成
- スケーリング因子($$\sqrt{d_k}$$)で勾配消失を防止
- 行列演算で効率的に実装可能</p>
<h4 id="32-multi-head-attention"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#32-multi-head-attention">3.2 Multi-Head Attention</a></h4>
<p>複数のattentionを並列に計算:
1. 入力を線形変換で複数の部分空間に投影
2. 各部分空間でattentionを計算
3. 結果を結合して再度線形変換</p>
<h3 id="4"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#4">4. モデルの詳細設定</a></h3>
<h4 id="41"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#41">4.1 基本設定</a></h4>
<ul>
<li>エンコーダー/デコーダー層数: 6</li>
<li>d_model (モデルの次元): 512</li>
<li>Attention heads: 8</li>
<li>Feed-forward層の次元: 2048</li>
</ul>
<h4 id="42"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#42">4.2 正規化と残差接続</a></h4>
<ul>
<li>各サブレイヤーの後にLayer Normalization</li>
<li>残差接続で勾配伝播を改善</li>
</ul>
<h3 id="5"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#5">5. 学習設定と最適化</a></h3>
<h4 id="51"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#51">5.1 トレーニングデータ</a></h4>
<ul>
<li>WMT 2014 英独翻訳データセット (450万文対)</li>
<li>WMT 2014 英仏翻訳データセット (3600万文対)</li>
</ul>
<h4 id="52"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#52">5.2 最適化設定</a></h4>
<ul>
<li>Adam optimizer使用</li>
<li>Warmup付き学習率スケジューリング</li>
<li>Dropout率: 0.1</li>
<li>Label smoothing: 0.1</li>
</ul>
<h3 id="6"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#6">6. 実験結果</a></h3>
<h4 id="61"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#61">6.1 機械翻訳性能</a></h4>
<ul>
<li>英独翻訳: BLEU 28.4 (当時の最高スコア)</li>
<li>英仏翻訳: BLEU 41.8</li>
<li>従来モデルより少ない計算コストで優れた性能を達成</li>
</ul>
<h4 id="62"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#62">6.2 解析タスクへの応用</a></h4>
<ul>
<li>英語構文解析でも高い性能を達成</li>
<li>少量データでも良好な汎化性能を示す</li>
</ul>
<h3 id="7-transformer"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#7-transformer">7. Transformerの利点</a></h3>
<ol>
<li>計算効率</li>
<li>並列処理が可能</li>
<li>
<p>トレーニング時間の大幅な削減</p>
</li>
<li>
<p>モデリング能力</p>
</li>
<li>長距離依存関係の効果的な学習</li>
<li>
<p>柔軟な注意機構による適応的な情報統合</p>
</li>
<li>
<p>解釈可能性</p>
</li>
<li>Attention分布の可視化が可能</li>
<li>モデルの判断過程を理解しやすい</li>
</ol>
<h3 id="8"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#8">8. 今後の展望</a></h3>
<p>著者らは以下の方向性を示しています:
- テキスト以外のモダリティへの適用
- 大規模な入出力の効率的な処理
- より非逐次的な生成方法の探究</p>
<h2 id="_9"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_9">まとめ</a></h2>
<p>Transformerは:
- Attention機構のみで高性能な系列変換を実現
- 並列処理による効率的な学習を可能に
- 現代の大規模言語モデルの基礎となる革新的なアーキテクチャ</p>
<p>この論文は深層学習の歴史における重要な転換点となり、現在のAI技術の発展に大きく貢献しています。</p>
<hr />
<h3 id="1-transformer"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#1-transformer">1. Transformerって何？</a></h3>
<h4 id="_10"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_10">簡単な説明</a></h4>
<p>Transformerは2017年にGoogleの研究者たちが発表した、人工知能の新しい仕組みです。
この技術は現在のChatGPTなど、最新のAI技術の土台となっている超重要な発明です。</p>
<h4 id="_11"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_11">主にできること</a></h4>
<ul>
<li>文章の翻訳</li>
<li>文章の理解</li>
<li>文章の生成</li>
</ul>
<p>例えば「こんにちは」を「Hello」に翻訳したり、質問に答えたりできます。</p>
<h3 id="2"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#2">2. なぜすごいの？</a></h3>
<h4 id="_12"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_12">従来の問題点</a></h4>
<p>それまでのAIには3つの大きな問題がありました：
1. 処理が遅い
2. 長い文章を理解するのが苦手
3. 前後の文脈を正確に理解できない</p>
<h4 id="transformer"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#transformer">Transformerの革新点</a></h4>
<p>これらの問題を解決するため、Transformerは「注目する仕組み（Attention）」を導入しました。</p>
<p>例えば：
「私は昨日買った本を読んだ」という文があった時
- 「買った」が「本」に関係している
- 「読んだ」も「本」に関係している
というように、文章の中の関連する部分同士を直接結びつけることができます。</p>
<h3 id="3-transformer"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#3-transformer">3. Transformerの仕組み</a></h3>
<h4 id="_13"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_13">全体の構造</a></h4>
<p>Transformerは大きく2つのパーツで構成されています：</p>
<ol>
<li>エンコーダー（入力を理解する部分）</li>
<li>デコーダー（出力を生成する部分）</li>
</ol>
<h4 id="_14"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_14">わかりやすい例え</a></h4>
<p>Transformerの仕組みを「翻訳する人」に例えると：</p>
<ol>
<li>エンコーダー = 日本語の文章を読んで理解する</li>
<li>デコーダー = 理解した内容を英語で表現する</li>
</ol>
<h3 id="4-attention"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#4-attention">4. 「注目」の仕組み（Attention）</a></h3>
<h4 id="_15"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_15">基本的な考え方</a></h4>
<p>人間が文章を読むときのように、重要な部分に「注目」する仕組みです。</p>
<p>例：
「私は赤いりんごを食べた」という文で
- 「食べた」という動作の対象は「りんご」
- 「赤い」は「りんご」の特徴</p>
<p>このように、文章の中の関連する部分同士をつなげて理解します。</p>
<h4 id="multi-head-attention"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#multi-head-attention">Multi-Head Attention</a></h4>
<p>さらにTransformerは、複数の視点から同時に文章を理解します。</p>
<p>例えると：
- 文法的な関係を見る目
- 意味的な関係を見る目
- 文脈を理解する目
など、複数の「目」で同時に文章を見ているようなものです。</p>
<h3 id="5_1"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#5_1">5. 位置の情報</a></h3>
<h4 id="_16"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_16">なぜ必要？</a></h4>
<p>「私は昨日公園で本を読んだ」という文で、
単語の順序が重要です。順番が変わると意味が変わってしまいます。</p>
<h4 id="_17"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_17">どうやって？</a></h4>
<p>Transformerは、各単語に「位置」の情報を追加します。
数学的な波（サイン波とコサイン波）を使って、各単語がどの位置にあるかを記録します。</p>
<h3 id="6_1"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#6_1">6. 実際の性能</a></h3>
<h4 id="_18"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_18">翻訳の例</a></h4>
<p>英語からドイツ語への翻訳で、当時の最高記録を達成：
- より正確な翻訳
- より自然な表現
- より速い処理</p>
<h4 id="_19"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_19">その他のできること</a></h4>
<ul>
<li>文章の要約</li>
<li>質問への回答</li>
<li>文章の分析</li>
</ul>
<h3 id="7"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#7">7. なぜ革命的なの？</a></h3>
<h4 id="ai"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#ai">AIの世界を変えた理由</a></h4>
<ol>
<li>処理速度が劇的に向上</li>
<li>より自然な言語理解が可能に</li>
<li>より長い文章も扱えるように</li>
</ol>
<h4 id="_20"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_20">現代への影響</a></h4>
<ul>
<li>ChatGPT</li>
<li>Google翻訳</li>
<li>その他の最新AI技術</li>
</ul>
<p>これらはすべてTransformerの技術を基礎としています。</p>
<h3 id="8_1"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#8_1">8. まとめ</a></h3>
<h4 id="transformer_1"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#transformer_1">Transformerの特徴</a></h4>
<ul>
<li>「注目」の仕組みで文章をより深く理解</li>
<li>複数の視点から同時に分析</li>
<li>高速で効率的な処理が可能</li>
</ul>
<h4 id="_21"><a class="toclink" href="../../2023/08/02/attention-is-all-you-need/#_21">今後の可能性</a></h4>
<ul>
<li>画像処理への応用</li>
<li>音声認識への応用</li>
<li>より高度な言語理解</li>
</ul>
<p>Transformerは、人工知能が人間の言語をより深く理解し、処理できるようになった重要な転換点といえます。現代のAI革命の出発点となった、とても重要な発明なのです。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-07-19 00:00:00+00:00">2023年7月19日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/digital-libraries/" class="md-meta__link">Digital Libraries</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="on-the-origin-of-llms-an-evolutionary-tree-and-graph-for-15821-large-language-models"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/">On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2307.09793">https://arxiv.org/abs/2307.09793</a></li>
<li><a href="https://arxiv.org/pdf/2307.09793">https://arxiv.org/pdf/2307.09793</a></li>
</ul>
<hr />
<h3 id="llm15821"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#llm15821">LLMの起源：15,821の大規模言語モデルの進化的ツリーとグラフ</a></h3>
<h3 id="_1"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#_1">序論</a></h3>
<p>本論文は、大規模言語モデル（LLM）の進化的な関係を明らかにすることを目的としています。特に、2022年以降のLLMの急速な発展とその多様性を体系的に理解するための研究です。</p>
<h3 id="_2"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#_2">研究の背景</a></h3>
<p>LLMは、特にChatGPTやBardのように、多くのユーザーに利用されています。毎週多くの新しいLLMが発表され、Hugging Faceに登録されていますが、それらの総合的なインデックスは存在しません。</p>
<h3 id="_3"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#_3">方法</a></h3>
<p>Hugging Faceに登録されているLLMの名称を用いて、階層的クラスタリングを実施しました。n-gramsやTF-IDF（Term Frequency-Inverse Document Frequency）を用いて、LLMのコミュニティを特定し、意味のあるサブグループに分類しました。</p>
<h3 id="_4"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#_4">結果</a></h3>
<p>本研究では、LLMのファミリーを特定し、それらを意味のあるサブグループに分類することに成功しました。また、15,821のLLMを視覚的に探索できるウェブアプリケーション「Constellation」を公開しました。</p>
<h3 id="_5"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#_5">結論</a></h3>
<p>「Constellation」を利用することで、研究者や開発者はLLMの関係性やトレンドを迅速に把握することが可能となりました。これは、LLMのさらなる発展や新しい研究の基盤となるでしょう。</p>
<h3 id="_6"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#_6">補足情報</a></h3>
<p>詳細な分析結果や視覚化ツールについては、<a href="https://constellation.sites.stanford.edu">こちら</a>で確認できます。</p>
<p><img alt="Output" src="https://constellation.sites.stanford.edu/sites/g/files/sbiybj29536/files/styles/card_1900x950/public/media/image/high_res_image-min_0.png?h=07184d4b&amp;itok=101XVkZ-" /></p>
<hr />
<h3 id="ai-generated-diagram"><a class="toclink" href="../../2023/07/19/an-evolutionary-tree-and-graph-for-15821-large-language-models/#ai-generated-diagram">AI generated diagram</a></h3>
<pre><code class="language-mermaid">flowchart TD
    A[データ収集] --&gt; B[パラメータ抽出]
    B --&gt; C[テキスト特徴抽出]
    C --&gt; D[階層的クラスタリング]
    D --&gt; E[コミュニティ検出]
    E --&gt; F[視覚化]
    F --&gt; G[ウェブアプリケーションの展開]
    G --&gt; H[結果のレビュー]
    H --&gt; I[結論: 大規模言語モデルの理解と分類を強化]

    A[Start: データ収集 \nHugging Faceからのモデル名、ダウンロード数、いいね数の収集]
    B[パラメータ抽出 \n正規表現を使用してモデル名からパラメータを抽出]
    C[テキスト特徴抽出 \nTF-IDFとn-gramsを使用してモデル名から特徴を抽出]
    D[階層的クラスタリング \n類似性に基づいてモデルをグループ化]
    E[コミュニティ検出 \nルーヴァン法を使用してグラフ内のコミュニティを検出]
    F[視覚化 \nインタラクティブなダイアグラムやワードクラウド、散布図をウェブアプリで提供]
    G[ウェブアプリケーションの展開 \nデータの動的探索を可能にする公開ウェブアプリケーション]
    H[結果のレビュー \n得られた結果を確認し、モデル間の関係を評価]
    I[End: 結論 \n大規模言語モデルの体系的な整理と分類を通じて理解を深める]
</code></pre>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-05-23 00:00:00+00:00">2023年5月23日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models"><a class="toclink" href="../../2023/05/23/do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models/">Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2305.13707">https://arxiv.org/abs/2305.13707</a></li>
<li><a href="https://arxiv.org/pdf/2305.13707">https://arxiv.org/pdf/2305.13707</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2023/05/23/do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models/#_1">序論</a></h3>
<p>本論文では、商用言語モデルAPIの使用料金が言語によって異なることを示し、その公平性について分析しています。特に、異なる言語で同じ情報を伝えるために必要なトークン数の違いが料金に与える影響を調査します。</p>
<h3 id="_2"><a class="toclink" href="../../2023/05/23/do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models/#_2">研究の目的</a></h3>
<p>言語モデルAPIの料金体系が言語間で公平であるかどうかを評価し、トークナイズの非均一性が料金とモデルの性能に与える影響を明らかにすることを目的としています。</p>
<h3 id="_3"><a class="toclink" href="../../2023/05/23/do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models/#_3">方法</a></h3>
<ul>
<li><strong>RQ1: トークン数の違い</strong>: 22の多様な言語でのトークン分割の影響を分析。</li>
<li><strong>RQ2: コスト</strong>: トークン数の違いがAPI使用料金に与える影響を評価。</li>
<li><strong>RQ3: モデルの有用性</strong>: トークン分割の非均一性がモデルの性能に与える影響を評価。</li>
<li><strong>RQ4: 社会経済的影響</strong>: API料金と性能の違いが経済的格差に与える影響を分析。</li>
</ul>
<h3 id="_4"><a class="toclink" href="../../2023/05/23/do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models/#_4">結果</a></h3>
<ol>
<li><strong>トークン数の違い</strong>: ラテン文字を使用する言語は他の言語よりも少ないトークン数で情報を伝えることができる。</li>
<li><strong>コスト</strong>: ラテン文字を使用する言語はAPI使用料金が低く、非ラテン文字を使用する言語は高い料金がかかる。</li>
<li><strong>モデルの有用性</strong>: 高いトークン分割率を持つ言語では、コンテキスト内学習の性能が低下する。</li>
<li><strong>社会経済的影響</strong>: 開発途上国の言語使用者は、高い料金を支払わなければならないことが多い。</li>
</ol>
<h3 id="_5"><a class="toclink" href="../../2023/05/23/do-all-languages-cost-the-same-tokenization-in-the-era-of-commercial-language-models/#_5">結論</a></h3>
<p>商用言語モデルAPIの料金体系とトークナイズの方法を見直し、より公平なシステムを構築することが求められます。NLPコミュニティもトークナイズの問題にもっと注目する必要があります。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-04-27 00:00:00+00:00">2023年4月27日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="harnessing-the-power-of-llms-in-practice-a-survey-on-chatgpt-and-beyond"><a class="toclink" href="../../2023/04/27/a-survey-on-chatgpt-and-beyond/">Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2304.13712">https://arxiv.org/abs/2304.13712</a></li>
<li><a href="https://arxiv.org/pdf/2304.13712">https://arxiv.org/pdf/2304.13712</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2023/04/27/a-survey-on-chatgpt-and-beyond/#_1">序論</a></h3>
<p>この論文は、大規模言語モデル（LLM）を実践的に活用するための包括的なガイドです。研究者やエンドユーザーが、LLMを効果的かつ効率的に利用するための実践的な知識と洞察を提供します。</p>
<h3 id="llm"><a class="toclink" href="../../2023/04/27/a-survey-on-chatgpt-and-beyond/#llm">LLMの紹介</a></h3>
<p>最新のGPTスタイルやBERTスタイルのLLMについて簡単に紹介し、それぞれのモデルがどのような訓練戦略、アーキテクチャ、使用ケースを持つかを説明します。</p>
<h3 id="_2"><a class="toclink" href="../../2023/04/27/a-survey-on-chatgpt-and-beyond/#_2">データの重要性</a></h3>
<p>LLMの性能に影響を与えるデータの役割について詳しく説明します。前処理データ、訓練データ、テストデータの重要性を強調し、それぞれのステージでのデータの影響を分析します。</p>
<h3 id="nlp"><a class="toclink" href="../../2023/04/27/a-survey-on-chatgpt-and-beyond/#nlp">NLPタスクの実践ガイド</a></h3>
<p>具体的なNLPタスクに対するLLMの使用ケースと非使用ケースについて詳しく説明します。テキスト分類、名前付きエンティティ認識（NER）、質問応答など、各タスクにおけるLLMの適用可能性を評価します。</p>
<h3 id="_3"><a class="toclink" href="../../2023/04/27/a-survey-on-chatgpt-and-beyond/#_3">結論</a></h3>
<p>LLMの利用に関する実践的な洞察とベストプラクティスを提供し、研究者や実務者が自分のNLPタスクでLLMの力を最大限に活用できるよう支援します。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-03-28 00:00:00+00:00">2023年3月28日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/machine-learning/" class="md-meta__link">Machine Learning</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="ecosystem-graphs-the-social-footprint-of-foundation-models"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/">Ecosystem Graphs: The Social Footprint of Foundation Models</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2303.15772">https://arxiv.org/abs/2303.15772</a></li>
<li><a href="https://arxiv.org/pdf/2303.15772">https://arxiv.org/pdf/2303.15772</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/#_1">序論</a></h3>
<p>この論文は、基礎モデル（Foundation Models, FM）が社会に与える影響を評価するための「Ecosystem Graphs」という新しいフレームワークを提案します。特に、ChatGPTやStable Diffusionなどのモデルがどのように利用され、影響を与えているかを可視化します。</p>
<h3 id="_2"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/#_2">背景</a></h3>
<p>基礎モデルは、言語、画像、コード、タンパク質構造など多岐にわたる分野で広く利用され、社会に大きな影響を与えています。しかし、これらのモデルが具体的にどのように影響を与えているかを詳細に理解するためのツールは不足しています。</p>
<h3 id="ecosystem-graphs"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/#ecosystem-graphs">Ecosystem Graphsの提案</a></h3>
<p>Ecosystem Graphsは、データセット、モデル、アプリケーションなどの「資産」をノードとして、技術的および社会的依存関係をエッジとしてグラフ構造で表現します。各ノードには詳細なメタデータが付与され、透明性を高めます。</p>
<h3 id="_3"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/#_3">実験と結果</a></h3>
<p>Ecosystem Graphsを用いて、262の資産（64のデータセット、128のモデル、70のアプリケーション）と356の依存関係をドキュメント化しました。このグラフを通じて、主要な資産や組織間の関係を明らかにし、透明性を向上させました。</p>
<h3 id="_4"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/#_4">考察</a></h3>
<p>Ecosystem Graphsは、研究者、産業界、政策立案者など多様なステークホルダーに対して価値を提供します。これにより、基礎モデルの開発と利用に関する理解が深まり、適切な対策が講じられることが期待されます。</p>
<h3 id="_5"><a class="toclink" href="../../2023/03/28/the-social-footprint-of-foundation-models/#_5">結論</a></h3>
<p>Ecosystem Graphsは、基礎モデルの社会的影響を評価するための強力なツールです。今後の研究や実践において、これを活用することで、より透明性の高いエコシステムの構築が可能となります。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-01-29 00:00:00+00:00">2023年1月29日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約3分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="large-language-models-are-zero-shot-reasoners"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/">Large Language Models are Zero-Shot Reasoners</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2205.11916">https://arxiv.org/abs/2205.11916</a></li>
<li><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html">https://proceedings.neurips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html</a></li>
<li><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf</a></li>
</ul>
<hr />
<h3 id="1"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#1">1. 研究の背景と目的</a></h3>
<h4 id="11"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#11">1.1 大規模言語モデルとプロンプティング</a></h4>
<p>近年、自然言語処理（NLP）の分野では、大規模言語モデル（LLM）が注目を集めています。これらのモデルは、GPT-3やPaLMなど、数十億から数千億のパラメータを持つ巨大なニューラルネットワークです。</p>
<p>LLMは通常、以下の2つの方法で使用されます：</p>
<ol>
<li>Few-shot learning（少数事例学習）：タスクの例をいくつか提示して、モデルにタスクを理解させる方法</li>
<li>Zero-shot learning（ゼロショット学習）：例を示さずに、タスクの説明だけでモデルに対応させる方法</li>
</ol>
<p>これらの方法を「プロンプティング」と呼びます。</p>
<h4 id="12-llm"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#12-llm">1.2 推論タスクにおけるLLMの課題</a></h4>
<p>LLMは多くのNLPタスクで優れた性能を示していますが、複雑な推論を要するタスク（例：算術問題や論理的推論）では課題が残っていました。</p>
<p>この問題に対処するため、「Chain of Thought（CoT）」というプロンプティング手法が提案されました。これは、解答の過程を段階的に示すことで、モデルにより複雑な推論を促す方法です。</p>
<h4 id="13"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#13">1.3 研究の目的</a></h4>
<p>本研究の主な目的は以下の通りです：</p>
<ol>
<li>LLMがゼロショット学習でも効果的に推論できることを示す</li>
<li>単一のプロンプトで様々な推論タスクに対応できることを実証する</li>
<li>LLMに隠された能力を探索し、理解を深める</li>
</ol>
<h3 id="2-zero-shot-chain-of-thought-zero-shot-cot"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#2-zero-shot-chain-of-thought-zero-shot-cot">2. 提案手法：Zero-shot Chain of Thought (Zero-shot-CoT)</a></h3>
<p>研究者らは、「Zero-shot Chain of Thought (Zero-shot-CoT)」という新しい手法を提案しました。</p>
<h4 id="21"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#21">2.1 手法の概要</a></h4>
<p>Zero-shot-CoTの核心は非常にシンプルです：</p>
<ol>
<li>質問の後に「Let's think step by step.」（一歩ずつ考えてみましょう）というプロンプトを追加する</li>
<li>これによりモデルに段階的な思考過程を生成させる</li>
</ol>
<h4 id="22-zero-shot-cot"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#22-zero-shot-cot">2.2 Zero-shot-CoTの実装</a></h4>
<p>Zero-shot-CoTは、以下の2段階のプロンプティングで実装されます：</p>
<ol>
<li>推論の抽出：</li>
<li>入力質問に「Let's think step by step.」を追加</li>
<li>
<p>モデルに思考過程を生成させる</p>
</li>
<li>
<p>回答の抽出：</p>
</li>
<li>生成された思考過程を含む全文をモデルに再入力</li>
<li>最終的な回答を抽出するためのプロンプトを追加（例：「Therefore, the answer is」）</li>
</ol>
<p><img alt="Figure 2" src="https://github.com/user-attachments/assets/a7b116c1-bc52-4031-a09b-3749a6fe290a" /></p>
<p>この手法により、モデルは段階的な推論を行い、最終的な回答を導き出すことができます。</p>
<h3 id="3"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#3">3. 実験設定</a></h3>
<h4 id="31"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#31">3.1 評価タスク</a></h4>
<p>研究者らは、以下の4カテゴリ、合計12のデータセットで実験を行いました：</p>
<ol>
<li>算術推論：SingleEq, AddSub, MultiArith, AQUA-RAT, GSM8K, SVAMP</li>
<li>常識推論：CommonsenseQA, StrategyQA</li>
<li>記号推論：Last Letter Concatenation, Coin Flip</li>
<li>その他の論理推論：Date Understanding, Tracking Shuffled Objects</li>
</ol>
<h4 id="32"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#32">3.2 使用モデル</a></h4>
<p>実験には以下のモデルが使用されました：</p>
<ul>
<li>GPT-3シリーズ（ada, babbage, curie, davinci）</li>
<li>InstructGPT3シリーズ</li>
<li>PaLM（8B, 62B, 540B）</li>
<li>その他（GPT-2, GPT-Neo, GPT-J, T0, OPT）</li>
</ul>
<h4 id="33"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#33">3.3 比較手法</a></h4>
<p>Zero-shot-CoTは、以下の手法と比較されました：</p>
<ol>
<li>標準的なZero-shotプロンプティング</li>
<li>Few-shotプロンプティング</li>
<li>Few-shot Chain of Thought (Few-shot-CoT)</li>
</ol>
<h3 id="4"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#4">4. 実験結果</a></h3>
<h4 id="41-zero-shot-cot"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#41-zero-shot-cot">4.1 Zero-shot-CoTの性能</a></h4>
<p>Zero-shot-CoTは、多くのタスクで標準的なZero-shotプロンプティングを大幅に上回る性能を示しました。</p>
<p>例えば：
- MultiArithタスク：17.7%から78.7%に向上
- GSM8Kタスク：10.4%から40.7%に向上</p>
<p><img alt="Table 1" src="https://github.com/user-attachments/assets/4cf971b2-ab7d-4d92-ac42-dae2784603a3" /></p>
<h4 id="42"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#42">4.2 他の手法との比較</a></h4>
<p>Zero-shot-CoTは、Few-shot-CoTには及ばないものの、標準的なFew-shotプロンプティングを上回る性能を示しました。</p>
<p><img alt="Table 2" src="https://github.com/user-attachments/assets/74d918fc-351b-4ff4-97e4-f1c7e324585f" /></p>
<p>特筆すべき点として、GSM8Kタスクでは、Zero-shot-CoTがファインチューニングされたGPT-3（175B）モデルを上回る性能を達成しました。</p>
<h4 id="43"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#43">4.3 モデルサイズの影響</a></h4>
<p>実験結果から、モデルのサイズが大きくなるほど、Zero-shot-CoTの効果が顕著になることが分かりました。</p>
<p><img alt="Figure 3" src="https://github.com/user-attachments/assets/3bc5ff6b-23be-428d-a831-2ef707bcbc83" /></p>
<p>小規模なモデルでは効果が限定的ですが、大規模モデルではZero-shot-CoTによって性能が大幅に向上しています。</p>
<h3 id="5"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#5">5. 分析と考察</a></h3>
<h4 id="51"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#51">5.1 プロンプトの影響</a></h4>
<p>研究者らは、様々なプロンプトを試し、その影響を調査しました。</p>
<p><img alt="Table 4" src="https://github.com/user-attachments/assets/198abcae-3807-4808-be85-9dedae93091c" /></p>
<p>結果から、推論を促すような表現（例：「Let's think step by step.」）が最も効果的であることが分かりました。一方で、ミスリーディングな表現や無関係な表現はモデルの性能を低下させました。</p>
<h4 id="52-few-shot-cot"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#52-few-shot-cot">5.2 Few-shot-CoTの例示の影響</a></h4>
<p>Few-shot-CoTの性能は、提示する例の選び方に大きく影響されることも明らかになりました。</p>
<p><img alt="Table 5" src="https://github.com/user-attachments/assets/9036e1f5-8934-4c42-91c0-e9ba464225fa" /></p>
<p>タスクとは無関係な例を使用すると性能が低下しますが、回答形式が一致している場合はその影響が軽減されます。</p>
<h4 id="53-zero-shot-cot"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#53-zero-shot-cot">5.3 Zero-shot-CoTの利点</a></h4>
<ol>
<li>タスク固有の例示が不要</li>
<li>単一のプロンプトで多様なタスクに対応可能</li>
<li>モデルの隠れた能力を引き出す可能性</li>
</ol>
<h3 id="6"><a class="toclink" href="../../2023/01/29/large-language-models-are-zero-shot-reasoners/#6">6. 結論と今後の展望</a></h3>
<p>本研究は、大規模言語モデルが適切なプロンプトさえあれば、ゼロショットで複雑な推論タスクを実行できることを示しました。</p>
<p>Zero-shot-CoTは：
1. 多様な推論タスクにおいて強力なベースラインとなる
2. モデルの隠れた能力を探索する新しい方法を提供する</p>
<p>今後の研究では、より広範な認知能力を引き出すプロンプトの開発や、Zero-shot-CoTのメカニズムのさらなる解明が期待されます。</p>
<p>この研究は、大規模言語モデルの可能性を再評価し、自然言語処理の新たな地平を切り開く重要な一歩となるでしょう。</p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2022-12-22 00:00:00+00:00">2022年12月22日</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../../category/computer-science/" class="md-meta__link">Computer Science</a>, 
              <a href="../../category/computation-and-language/" class="md-meta__link">Computation and Language</a>, 
              <a href="../../category/synthetic-biology/" class="md-meta__link">Synthetic Biology</a></li>
        
        
          
          <li class="md-meta__item">
            
              このページは約1分で読めます
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="language-models-generalize-beyond-natural-proteins"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/">Language models generalize beyond natural proteins</a></h2>
<ul>
<li><a href="https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1">https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1</a></li>
<li><a href="https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1.full.pdf">https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1.full.pdf</a></li>
</ul>
<hr />
<h3 id="_1"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_1">序論</a></h3>
<p>この論文では、自然界のタンパク質を超えて新しいタンパク質を生成するための言語モデルの一般化能力について調査します。特に、固定バックボーン設計と構造がモデルからサンプリングされる非制約生成の2つのタンパク質設計タスクに焦点を当てます。</p>
<h3 id="_2"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_2">研究の背景</a></h3>
<p>従来のタンパク質設計は、自然界のパーツを使った手動のボトムアップアプローチが主流でした。しかし、生物の複雑性により、トップダウンの設計は難しいとされています。近年の自然言語処理の進展により、タンパク質のシーケンスデータから機能に関する情報を学習するモデルの開発が進んでいます。</p>
<h3 id="_3"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_3">研究目的</a></h3>
<p>本研究は、タンパク質シーケンスデータの学習モデルがどのように機能を予測し、新しいタンパク質を生成するかを明らかにすることを目的としています。</p>
<h3 id="_4"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_4">方法</a></h3>
<ul>
<li><strong>データセット</strong>: タンパク質シーケンスの大規模データセットを使用。</li>
<li><strong>モデル</strong>: 言語モデルを用いたタンパク質のシーケンス生成。</li>
<li><strong>タスク</strong>: 固定バックボーン設計と非制約生成の2つのタンパク質設計タスクに焦点を当てた実験を実施。</li>
</ul>
<h3 id="_5"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_5">結果</a></h3>
<ul>
<li>言語モデルは、トレーニングデータとして使用されたシーケンスだけでなく、新しいシーケンスも生成する能力があることを示しました。</li>
<li>固定バックボーン設計では、指定された構造に基づいたタンパク質を生成する能力が確認されました。</li>
<li>非制約生成では、モデルはサンプリングされた構造から新しいタンパク質シーケンスを生成する能力を示しました。</li>
</ul>
<h3 id="_6"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_6">考察</a></h3>
<ul>
<li>言語モデルは、タンパク質のシーケンスデータからパターンを学習し、進化の情報をエンコードする能力があります。</li>
<li>トップダウン設計が難しいとされる中、言語モデルを用いることで新しいアプローチが可能となります。</li>
</ul>
<h3 id="_7"><a class="toclink" href="../../2022/12/22/language-models-generalize-beyond-natural-proteins/#_7">結論</a></h3>
<p>言語モデルは、自然界のタンパク質を超えて新しいタンパク質を生成する強力なツールであり、生物学的および医療的応用において大きな可能性を秘めています。今後の研究では、これらのモデルの性能向上と新しい応用分野の開拓が期待されます。</p>
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  <a class="md-pagination__link" href="../../">1</a> <a class="md-pagination__link" href="../2/">2</a> <span class="md-pagination__current">3</span> <a class="md-pagination__link" href="../4/">4</a> <a class="md-pagination__link" href="../5/">5</a> <a class="md-pagination__link" href="../6/">6</a>
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2014 - 2025 Sojiro's Blog. All rights reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://x.com/sojiro14" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/sojiro14" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\u30b3\u30d4\u30fc\u3057\u307e\u3057\u305f", "clipboard.copy": "\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u3078\u30b3\u30d4\u30fc", "search.result.more.one": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3082\u30461\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.more.other": "\u3053\u306e\u30da\u30fc\u30b8\u5185\u306b\u3042\u3068#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.none": "\u4f55\u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f", "search.result.one": "1\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.other": "#\u4ef6\u898b\u3064\u304b\u308a\u307e\u3057\u305f", "search.result.placeholder": "\u691c\u7d22\u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044", "search.result.term.missing": "\u691c\u7d22\u306b\u542b\u307e\u308c\u306a\u3044", "select.version": "\u30d0\u30fc\u30b8\u30e7\u30f3\u5207\u308a\u66ff\u3048"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>